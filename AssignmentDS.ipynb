{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/ashan/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel0      0.0\n",
       "pixel1      0.0\n",
       "pixel2      0.0\n",
       "pixel3      0.0\n",
       "pixel4      0.0\n",
       "           ... \n",
       "pixel779    0.0\n",
       "pixel780    0.0\n",
       "pixel781    0.0\n",
       "pixel782    0.0\n",
       "pixel783    0.0\n",
       "Length: 784, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(train_images.drop('label', axis=1).mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0        1       0       0       0       0       0       0       0       0   \n",
       "1        0       0       0       0       0       0       0       0       0   \n",
       "2        1       0       0       0       0       0       0       0       0   \n",
       "3        4       0       0       0       0       0       0       0       0   \n",
       "4        0       0       0       0       0       0       0       0       0   \n",
       "..     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "495      1       0       0       0       0       0       0       0       0   \n",
       "496      4       0       0       0       0       0       0       0       0   \n",
       "497      1       0       0       0       0       0       0       0       0   \n",
       "498      5       0       0       0       0       0       0       0       0   \n",
       "499      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "     pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0         0  ...         0         0         0         0         0         0   \n",
       "1         0  ...         0         0         0         0         0         0   \n",
       "2         0  ...         0         0         0         0         0         0   \n",
       "3         0  ...         0         0         0         0         0         0   \n",
       "4         0  ...         0         0         0         0         0         0   \n",
       "..      ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "495       0  ...         0         0         0         0         0         0   \n",
       "496       0  ...         0         0         0         0         0         0   \n",
       "497       0  ...         0         0         0         0         0         0   \n",
       "498       0  ...         0         0         0         0         0         0   \n",
       "499       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "     pixel780  pixel781  pixel782  pixel783  \n",
       "0           0         0         0         0  \n",
       "1           0         0         0         0  \n",
       "2           0         0         0         0  \n",
       "3           0         0         0         0  \n",
       "4           0         0         0         0  \n",
       "..        ...       ...       ...       ...  \n",
       "495         0         0         0         0  \n",
       "496         0         0         0         0  \n",
       "497         0         0         0         0  \n",
       "498         0         0         0         0  \n",
       "499         0         0         0         0  \n",
       "\n",
       "[500 rows x 785 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_images['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_images.drop(columns = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier =KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_prediction = knn_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.77380952380953"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,knn_prediction)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linear.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prep = model_linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.20238095238095"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred=y_prep) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.58333333333333"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred=pred)* 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(learning_rate=1.0,max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=1.0, loss='deviance', max_depth=1,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.36904761904762"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred=prediction) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifier = RandomForestClassifier(max_depth=20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pre = random_forest_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.14285714285714"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,random_pre) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifier = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "                     oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pred = tree_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.27380952380953"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred=tree_pred) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_nb.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_pred = gaussian_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5463095238095238"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,gaussian_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(512,activation='relu',input_shape=(28 * 28,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(10, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ashan/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ashan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ashan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ashan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /home/ashan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ashan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ashan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ashan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ashan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2567 - acc: 0.9251\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.1053 - acc: 0.9687\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0706 - acc: 0.9792\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0520 - acc: 0.9844\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0397 - acc: 0.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbffc304a50>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  0   2   3   4   5   6   7   8   9  11  13  16  18  19  20  22  23  24\n",
      "  25  26  27  28  29  30  32  33  34  35  36  38  39  40  41  42  43  44\n",
      "  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  65\n",
      "  67  68  69  70  72  73  74  76  77  79  80  81  82  83  84  86  87  88\n",
      "  91  92  93  94  95  96  97  98  99 100 101 104 105 106 109 110 111 112\n",
      " 113 114 115 116 117 119 120 121 122 123 124 125 126 128 129 130 131 133\n",
      " 135 136 137 138 139 141 143 144 145 146 147 148 149 150 151 152 153 154\n",
      " 155 156 158 160 161 162 163 164 166 167 168 169 171 173 174 176 177 178\n",
      " 180 181 182 183 184 185 186 187 189 190 191 192 193 195 197 198 199 200\n",
      " 201 202 203 204 206 207 208 209 212 214 215 216 217 218 219 220 221 222\n",
      " 223 225 226 227 228 229 230 232 234 236 237 238 240 241 242 243 244 245\n",
      " 246 248 251 252 253 254 255 256 257 258 259 260 261 262 265 266 267 269\n",
      " 270 271 273 274 275 276 277 278 279 280 281 282 284 285 286 287 288 289\n",
      " 290 291 292 293 294 295 296 297 299 300 302 303 304 305 306 307 309 311\n",
      " 312 313 314 315 316 317 320 321 322 323 324 325 326 327 328 329 331 332\n",
      " 333 334 335 336 338 339 341 342 343 344 346 347 349 351 352 355 357 359\n",
      " 360 361 362 363 365 366 367 368 369 370 371 373 374 375 376 377 378 379\n",
      " 380 381 383 384 386 387 388 390 392 393 394 395 396 397 398 399 402 403\n",
      " 404 405 406 407 408 409 410 411 415 418 419 422 423 424 425 426 427 428\n",
      " 429 430 431 433 435 436 437 438 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 459 460 461 462 464 467 469 470 472 474 475\n",
      " 476 477 478 479 480 481 483 484 485 486 487 488 489 490 491 492 493 494\n",
      " 495 496 497 498 499 501 502 503 505 506 507 508 509 510 511 513 514 517\n",
      " 520 521 522 523 524 526 527 528 529 530 531 532 533 534 535 536 537 539\n",
      " 540 541 542 543 544 545 547 548 549 550 551 552 553 554 555 556 557 558\n",
      " 559 561 563 565 568] TEST: [  1  10  12  14  15  17  21  31  37  45  46  64  66  71  75  78  85  89\n",
      "  90 102 103 107 108 118 127 132 134 140 142 157 159 165 170 172 175 179\n",
      " 188 194 196 205 210 211 213 224 231 233 235 239 247 249 250 263 264 268\n",
      " 272 283 298 301 308 310 318 319 330 337 340 345 348 350 353 354 356 358\n",
      " 364 372 382 385 389 391 400 401 412 413 414 416 417 420 421 432 434 439\n",
      " 457 458 463 465 466 468 471 473 482 500 504 512 515 516 518 519 525 538\n",
      " 546 560 562 564 566 567]\n",
      "TRAIN: [  0   1   2   3   4   5   9  10  11  12  13  14  15  16  17  18  19  21\n",
      "  22  23  24  25  26  27  28  29  31  32  33  35  36  37  39  40  41  42\n",
      "  43  44  45  46  47  48  50  51  52  53  57  58  61  62  63  64  66  67\n",
      "  69  70  71  72  73  74  75  77  78  79  80  81  82  83  84  85  86  87\n",
      "  88  89  90  91  92  93  94  95  98  99 102 103 104 105 106 107 108 109\n",
      " 110 111 114 115 116 117 118 119 120 121 122 123 125 127 128 129 130 131\n",
      " 132 133 134 135 136 138 139 140 141 142 143 145 146 147 148 149 150 151\n",
      " 152 156 157 159 160 161 163 164 165 166 167 168 169 170 172 173 174 175\n",
      " 176 177 178 179 180 181 182 183 184 187 188 189 191 192 193 194 195 196\n",
      " 197 198 199 200 201 203 204 205 207 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 226 227 228 231 232 233 234 235 237 238 239\n",
      " 241 244 245 247 248 249 250 251 253 254 255 256 257 258 259 260 263 264\n",
      " 265 266 267 268 269 270 272 273 274 275 277 279 280 283 284 285 286 287\n",
      " 288 289 290 291 292 294 295 296 297 298 300 301 302 304 305 307 308 309\n",
      " 310 311 312 314 315 317 318 319 321 322 323 324 326 327 328 329 330 331\n",
      " 335 337 340 341 342 344 345 348 349 350 351 352 353 354 356 358 359 360\n",
      " 362 363 364 365 368 369 370 371 372 373 374 375 376 377 379 381 382 383\n",
      " 385 386 387 388 389 391 393 394 395 396 397 398 399 400 401 402 403 404\n",
      " 405 407 409 410 411 412 413 414 416 417 418 419 420 421 422 423 424 425\n",
      " 426 428 430 431 432 433 434 435 438 439 442 443 444 445 446 447 448 449\n",
      " 450 451 452 455 456 457 458 459 460 461 462 463 464 465 466 467 468 470\n",
      " 471 472 473 475 476 477 479 480 481 482 483 484 485 486 487 488 491 493\n",
      " 494 495 496 497 498 500 501 504 506 507 508 509 510 511 512 513 515 516\n",
      " 517 518 519 520 521 522 524 525 528 529 530 532 533 535 536 537 538 539\n",
      " 540 541 543 544 545 546 548 549 551 552 554 555 556 557 558 559 560 561\n",
      " 562 564 566 567 568] TEST: [  6   7   8  20  30  34  38  49  54  55  56  59  60  65  68  76  96  97\n",
      " 100 101 112 113 124 126 137 144 153 154 155 158 162 171 185 186 190 202\n",
      " 206 208 225 229 230 236 240 242 243 246 252 261 262 271 276 278 281 282\n",
      " 293 299 303 306 313 316 320 325 332 333 334 336 338 339 343 346 347 355\n",
      " 357 361 366 367 378 380 384 390 392 406 408 415 427 429 436 437 440 441\n",
      " 453 454 469 474 478 489 490 492 499 502 503 505 514 523 526 527 531 534\n",
      " 542 547 550 553 563 565]\n",
      "TRAIN: [  0   1   3   6   7   8   9  10  11  12  13  14  15  16  17  19  20  21\n",
      "  23  24  25  27  28  29  30  31  32  34  36  37  38  40  41  42  43  45\n",
      "  46  47  48  49  50  53  54  55  56  57  58  59  60  62  64  65  66  67\n",
      "  68  69  70  71  72  75  76  77  78  79  80  82  83  84  85  86  87  89\n",
      "  90  91  94  95  96  97  98  99 100 101 102 103 104 107 108 109 110 111\n",
      " 112 113 115 117 118 119 121 123 124 125 126 127 128 129 130 131 132 134\n",
      " 137 138 139 140 142 143 144 147 148 149 151 152 153 154 155 156 157 158\n",
      " 159 161 162 163 165 166 169 170 171 172 174 175 177 178 179 180 182 183\n",
      " 184 185 186 187 188 189 190 192 193 194 196 197 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 222 223 224 225 226 227 228\n",
      " 229 230 231 233 234 235 236 237 239 240 242 243 244 246 247 248 249 250\n",
      " 251 252 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271\n",
      " 272 273 274 275 276 277 278 279 280 281 282 283 286 287 288 291 292 293\n",
      " 294 296 298 299 300 301 303 304 305 306 307 308 309 310 313 314 316 317\n",
      " 318 319 320 321 323 324 325 326 327 328 330 331 332 333 334 335 336 337\n",
      " 338 339 340 341 343 345 346 347 348 349 350 352 353 354 355 356 357 358\n",
      " 359 360 361 363 364 366 367 368 369 370 371 372 373 374 376 377 378 380\n",
      " 382 383 384 385 387 388 389 390 391 392 394 396 397 398 400 401 402 404\n",
      " 405 406 407 408 410 411 412 413 414 415 416 417 418 419 420 421 422 423\n",
      " 427 429 430 431 432 434 435 436 437 438 439 440 441 442 443 445 446 447\n",
      " 448 449 450 451 453 454 455 456 457 458 459 460 461 462 463 465 466 468\n",
      " 469 470 471 472 473 474 475 476 478 480 482 483 485 486 488 489 490 492\n",
      " 495 496 497 498 499 500 502 503 504 505 507 509 510 511 512 513 514 515\n",
      " 516 518 519 521 522 523 524 525 526 527 528 529 531 533 534 535 536 537\n",
      " 538 540 541 542 543 544 546 547 550 551 552 553 556 558 559 560 562 563\n",
      " 564 565 566 567 568] TEST: [  2   4   5  18  22  26  33  35  39  44  51  52  61  63  73  74  81  88\n",
      "  92  93 105 106 114 116 120 122 133 135 136 141 145 146 150 160 164 167\n",
      " 168 173 176 181 191 195 198 199 200 218 219 220 221 232 238 241 245 253\n",
      " 254 255 284 285 289 290 295 297 302 311 312 315 322 329 342 344 351 362\n",
      " 365 375 379 381 386 393 395 399 403 409 424 425 426 428 433 444 452 464\n",
      " 467 477 479 481 484 487 491 493 494 501 506 508 517 520 530 532 539 545\n",
      " 548 549 554 555 557 561]\n",
      "TRAIN: [  0   1   2   4   5   6   7   8   9  10  12  14  15  17  18  20  21  22\n",
      "  23  26  28  30  31  33  34  35  37  38  39  42  43  44  45  46  47  48\n",
      "  49  50  51  52  53  54  55  56  57  59  60  61  62  63  64  65  66  68\n",
      "  69  70  71  72  73  74  75  76  78  81  82  84  85  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 105 106 107 108 112 113\n",
      " 114 115 116 118 119 120 122 123 124 126 127 128 130 131 132 133 134 135\n",
      " 136 137 140 141 142 143 144 145 146 147 148 150 151 153 154 155 157 158\n",
      " 159 160 162 163 164 165 167 168 169 170 171 172 173 174 175 176 177 178\n",
      " 179 180 181 183 185 186 187 188 190 191 192 194 195 196 197 198 199 200\n",
      " 201 202 203 205 206 207 208 209 210 211 213 218 219 220 221 222 224 225\n",
      " 227 229 230 231 232 233 235 236 238 239 240 241 242 243 244 245 246 247\n",
      " 249 250 252 253 254 255 256 257 261 262 263 264 265 268 270 271 272 273\n",
      " 276 277 278 279 281 282 283 284 285 288 289 290 291 292 293 295 297 298\n",
      " 299 301 302 303 304 305 306 308 310 311 312 313 314 315 316 318 319 320\n",
      " 321 322 324 325 329 330 332 333 334 335 336 337 338 339 340 341 342 343\n",
      " 344 345 346 347 348 349 350 351 353 354 355 356 357 358 359 361 362 364\n",
      " 365 366 367 368 369 370 372 373 375 377 378 379 380 381 382 383 384 385\n",
      " 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 403 405\n",
      " 406 408 409 411 412 413 414 415 416 417 418 419 420 421 423 424 425 426\n",
      " 427 428 429 430 431 432 433 434 436 437 439 440 441 442 444 448 451 452\n",
      " 453 454 457 458 459 461 463 464 465 466 467 468 469 471 472 473 474 477\n",
      " 478 479 480 481 482 484 486 487 488 489 490 491 492 493 494 499 500 501\n",
      " 502 503 504 505 506 508 509 510 511 512 514 515 516 517 518 519 520 521\n",
      " 522 523 525 526 527 528 529 530 531 532 534 536 537 538 539 540 542 543\n",
      " 544 545 546 547 548 549 550 551 553 554 555 557 558 559 560 561 562 563\n",
      " 564 565 566 567 568] TEST: [  3  11  13  16  19  24  25  27  29  32  36  40  41  58  67  77  79  80\n",
      "  83  86 104 109 110 111 117 121 125 129 138 139 149 152 156 161 166 182\n",
      " 184 189 193 204 212 214 215 216 217 223 226 228 234 237 248 251 258 259\n",
      " 260 266 267 269 274 275 280 286 287 294 296 300 307 309 317 323 326 327\n",
      " 328 331 352 360 363 371 374 376 402 404 407 410 422 435 438 443 445 446\n",
      " 447 449 450 455 456 460 462 470 475 476 483 485 495 496 497 498 507 513\n",
      " 524 533 535 541 552 556]\n",
      "TRAIN: [  1   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  24  25  26  27  29  30  31  32  33  34  35  36  37  38  39\n",
      "  40  41  44  45  46  49  51  52  54  55  56  58  59  60  61  63  64  65\n",
      "  66  67  68  71  73  74  75  76  77  78  79  80  81  83  85  86  88  89\n",
      "  90  92  93  96  97 100 101 102 103 104 105 106 107 108 109 110 111 112\n",
      " 113 114 116 117 118 120 121 122 124 125 126 127 129 132 133 134 135 136\n",
      " 137 138 139 140 141 142 144 145 146 149 150 152 153 154 155 156 157 158\n",
      " 159 160 161 162 164 165 166 167 168 170 171 172 173 175 176 179 181 182\n",
      " 184 185 186 188 189 190 191 193 194 195 196 198 199 200 202 204 205 206\n",
      " 208 210 211 212 213 214 215 216 217 218 219 220 221 223 224 225 226 228\n",
      " 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 245 246 247\n",
      " 248 249 250 251 252 253 254 255 258 259 260 261 262 263 264 266 267 268\n",
      " 269 271 272 274 275 276 278 280 281 282 283 284 285 286 287 289 290 293\n",
      " 294 295 296 297 298 299 300 301 302 303 306 307 308 309 310 311 312 313\n",
      " 315 316 317 318 319 320 322 323 325 326 327 328 329 330 331 332 333 334\n",
      " 336 337 338 339 340 342 343 344 345 346 347 348 350 351 352 353 354 355\n",
      " 356 357 358 360 361 362 363 364 365 366 367 371 372 374 375 376 378 379\n",
      " 380 381 382 384 385 386 389 390 391 392 393 395 399 400 401 402 403 404\n",
      " 406 407 408 409 410 412 413 414 415 416 417 420 421 422 424 425 426 427\n",
      " 428 429 432 433 434 435 436 437 438 439 440 441 443 444 445 446 447 449\n",
      " 450 452 453 454 455 456 457 458 460 462 463 464 465 466 467 468 469 470\n",
      " 471 473 474 475 476 477 478 479 481 482 483 484 485 487 489 490 491 492\n",
      " 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 512 513\n",
      " 514 515 516 517 518 519 520 523 524 525 526 527 530 531 532 533 534 535\n",
      " 538 539 541 542 545 546 547 548 549 550 552 553 554 555 556 557 560 561\n",
      " 562 563 564 565 566 567] TEST: [  0   9  23  28  42  43  47  48  50  53  57  62  69  70  72  82  84  87\n",
      "  91  94  95  98  99 115 119 123 128 130 131 143 147 148 151 163 169 174\n",
      " 177 178 180 183 187 192 197 201 203 207 209 222 227 244 256 257 265 270\n",
      " 273 277 279 288 291 292 304 305 314 321 324 335 341 349 359 368 369 370\n",
      " 373 377 383 387 388 394 396 397 398 405 411 418 419 423 430 431 442 448\n",
      " 451 459 461 472 480 486 488 509 510 511 521 522 528 529 536 537 540 543\n",
      " 544 551 558 559 568]\n"
     ]
    }
   ],
   "source": [
    "for train_index , test_index in kfold.split(breast_cancer.data):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train ,x_test  = breast_cancer.data[train_index] ,breast_cancer.data[test_index]\\\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  0   2   3   4   5   6   7   8   9  11  13  16  18  19  20  22  23  24\n",
      "  25  26  27  28  29  30  32  33  34  35  36  38  39  40  41  42  43  44\n",
      "  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  65\n",
      "  67  68  69  70  72  73  74  76  77  79  80  81  82  83  84  86  87  88\n",
      "  91  92  93  94  95  96  97  98  99 100 101 104 105 106 109 110 111 112\n",
      " 113 114 115 116 117 119 120 121 122 123 124 125 126 128 129 130 131 133\n",
      " 135 136 137 138 139 141 143 144 145 146 147 148 149 150 151 152 153 154\n",
      " 155 156 158 160 161 162 163 164 166 167 168 169 171 173 174 176 177 178\n",
      " 180 181 182 183 184 185 186 187 189 190 191 192 193 195 197 198 199 200\n",
      " 201 202 203 204 206 207 208 209 212 214 215 216 217 218 219 220 221 222\n",
      " 223 225 226 227 228 229 230 232 234 236 237 238 240 241 242 243 244 245\n",
      " 246 248 251 252 253 254 255 256 257 258 259 260 261 262 265 266 267 269\n",
      " 270 271 273 274 275 276 277 278 279 280 281 282 284 285 286 287 288 289\n",
      " 290 291 292 293 294 295 296 297 299 300 302 303 304 305 306 307 309 311\n",
      " 312 313 314 315 316 317 320 321 322 323 324 325 326 327 328 329 331 332\n",
      " 333 334 335 336 338 339 341 342 343 344 346 347 349 351 352 355 357 359\n",
      " 360 361 362 363 365 366 367 368 369 370 371 373 374 375 376 377 378 379\n",
      " 380 381 383 384 386 387 388 390 392 393 394 395 396 397 398 399 402 403\n",
      " 404 405 406 407 408 409 410 411 415 418 419 422 423 424 425 426 427 428\n",
      " 429 430 431 433 435 436 437 438 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 459 460 461 462 464 467 469 470 472 474 475\n",
      " 476 477 478 479 480 481 483 484 485 486 487 488 489 490 491 492 493 494\n",
      " 495 496 497 498 499 501 502 503 505 506 507 508 509 510 511 513 514 517\n",
      " 520 521 522 523 524 526 527 528 529 530 531 532 533 534 535 536 537 539\n",
      " 540 541 542 543 544 545 547 548 549 550 551 552 553 554 555 556 557 558\n",
      " 559 561 563 565 568] TEST: [  1  10  12  14  15  17  21  31  37  45  46  64  66  71  75  78  85  89\n",
      "  90 102 103 107 108 118 127 132 134 140 142 157 159 165 170 172 175 179\n",
      " 188 194 196 205 210 211 213 224 231 233 235 239 247 249 250 263 264 268\n",
      " 272 283 298 301 308 310 318 319 330 337 340 345 348 350 353 354 356 358\n",
      " 364 372 382 385 389 391 400 401 412 413 414 416 417 420 421 432 434 439\n",
      " 457 458 463 465 466 468 471 473 482 500 504 512 515 516 518 519 525 538\n",
      " 546 560 562 564 566 567]\n",
      "TRAIN: [  0   1   2   3   4   5   9  10  11  12  13  14  15  16  17  18  19  21\n",
      "  22  23  24  25  26  27  28  29  31  32  33  35  36  37  39  40  41  42\n",
      "  43  44  45  46  47  48  50  51  52  53  57  58  61  62  63  64  66  67\n",
      "  69  70  71  72  73  74  75  77  78  79  80  81  82  83  84  85  86  87\n",
      "  88  89  90  91  92  93  94  95  98  99 102 103 104 105 106 107 108 109\n",
      " 110 111 114 115 116 117 118 119 120 121 122 123 125 127 128 129 130 131\n",
      " 132 133 134 135 136 138 139 140 141 142 143 145 146 147 148 149 150 151\n",
      " 152 156 157 159 160 161 163 164 165 166 167 168 169 170 172 173 174 175\n",
      " 176 177 178 179 180 181 182 183 184 187 188 189 191 192 193 194 195 196\n",
      " 197 198 199 200 201 203 204 205 207 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 226 227 228 231 232 233 234 235 237 238 239\n",
      " 241 244 245 247 248 249 250 251 253 254 255 256 257 258 259 260 263 264\n",
      " 265 266 267 268 269 270 272 273 274 275 277 279 280 283 284 285 286 287\n",
      " 288 289 290 291 292 294 295 296 297 298 300 301 302 304 305 307 308 309\n",
      " 310 311 312 314 315 317 318 319 321 322 323 324 326 327 328 329 330 331\n",
      " 335 337 340 341 342 344 345 348 349 350 351 352 353 354 356 358 359 360\n",
      " 362 363 364 365 368 369 370 371 372 373 374 375 376 377 379 381 382 383\n",
      " 385 386 387 388 389 391 393 394 395 396 397 398 399 400 401 402 403 404\n",
      " 405 407 409 410 411 412 413 414 416 417 418 419 420 421 422 423 424 425\n",
      " 426 428 430 431 432 433 434 435 438 439 442 443 444 445 446 447 448 449\n",
      " 450 451 452 455 456 457 458 459 460 461 462 463 464 465 466 467 468 470\n",
      " 471 472 473 475 476 477 479 480 481 482 483 484 485 486 487 488 491 493\n",
      " 494 495 496 497 498 500 501 504 506 507 508 509 510 511 512 513 515 516\n",
      " 517 518 519 520 521 522 524 525 528 529 530 532 533 535 536 537 538 539\n",
      " 540 541 543 544 545 546 548 549 551 552 554 555 556 557 558 559 560 561\n",
      " 562 564 566 567 568] TEST: [  6   7   8  20  30  34  38  49  54  55  56  59  60  65  68  76  96  97\n",
      " 100 101 112 113 124 126 137 144 153 154 155 158 162 171 185 186 190 202\n",
      " 206 208 225 229 230 236 240 242 243 246 252 261 262 271 276 278 281 282\n",
      " 293 299 303 306 313 316 320 325 332 333 334 336 338 339 343 346 347 355\n",
      " 357 361 366 367 378 380 384 390 392 406 408 415 427 429 436 437 440 441\n",
      " 453 454 469 474 478 489 490 492 499 502 503 505 514 523 526 527 531 534\n",
      " 542 547 550 553 563 565]\n",
      "TRAIN: [  0   1   3   6   7   8   9  10  11  12  13  14  15  16  17  19  20  21\n",
      "  23  24  25  27  28  29  30  31  32  34  36  37  38  40  41  42  43  45\n",
      "  46  47  48  49  50  53  54  55  56  57  58  59  60  62  64  65  66  67\n",
      "  68  69  70  71  72  75  76  77  78  79  80  82  83  84  85  86  87  89\n",
      "  90  91  94  95  96  97  98  99 100 101 102 103 104 107 108 109 110 111\n",
      " 112 113 115 117 118 119 121 123 124 125 126 127 128 129 130 131 132 134\n",
      " 137 138 139 140 142 143 144 147 148 149 151 152 153 154 155 156 157 158\n",
      " 159 161 162 163 165 166 169 170 171 172 174 175 177 178 179 180 182 183\n",
      " 184 185 186 187 188 189 190 192 193 194 196 197 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 222 223 224 225 226 227 228\n",
      " 229 230 231 233 234 235 236 237 239 240 242 243 244 246 247 248 249 250\n",
      " 251 252 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271\n",
      " 272 273 274 275 276 277 278 279 280 281 282 283 286 287 288 291 292 293\n",
      " 294 296 298 299 300 301 303 304 305 306 307 308 309 310 313 314 316 317\n",
      " 318 319 320 321 323 324 325 326 327 328 330 331 332 333 334 335 336 337\n",
      " 338 339 340 341 343 345 346 347 348 349 350 352 353 354 355 356 357 358\n",
      " 359 360 361 363 364 366 367 368 369 370 371 372 373 374 376 377 378 380\n",
      " 382 383 384 385 387 388 389 390 391 392 394 396 397 398 400 401 402 404\n",
      " 405 406 407 408 410 411 412 413 414 415 416 417 418 419 420 421 422 423\n",
      " 427 429 430 431 432 434 435 436 437 438 439 440 441 442 443 445 446 447\n",
      " 448 449 450 451 453 454 455 456 457 458 459 460 461 462 463 465 466 468\n",
      " 469 470 471 472 473 474 475 476 478 480 482 483 485 486 488 489 490 492\n",
      " 495 496 497 498 499 500 502 503 504 505 507 509 510 511 512 513 514 515\n",
      " 516 518 519 521 522 523 524 525 526 527 528 529 531 533 534 535 536 537\n",
      " 538 540 541 542 543 544 546 547 550 551 552 553 556 558 559 560 562 563\n",
      " 564 565 566 567 568] TEST: [  2   4   5  18  22  26  33  35  39  44  51  52  61  63  73  74  81  88\n",
      "  92  93 105 106 114 116 120 122 133 135 136 141 145 146 150 160 164 167\n",
      " 168 173 176 181 191 195 198 199 200 218 219 220 221 232 238 241 245 253\n",
      " 254 255 284 285 289 290 295 297 302 311 312 315 322 329 342 344 351 362\n",
      " 365 375 379 381 386 393 395 399 403 409 424 425 426 428 433 444 452 464\n",
      " 467 477 479 481 484 487 491 493 494 501 506 508 517 520 530 532 539 545\n",
      " 548 549 554 555 557 561]\n",
      "TRAIN: [  0   1   2   4   5   6   7   8   9  10  12  14  15  17  18  20  21  22\n",
      "  23  26  28  30  31  33  34  35  37  38  39  42  43  44  45  46  47  48\n",
      "  49  50  51  52  53  54  55  56  57  59  60  61  62  63  64  65  66  68\n",
      "  69  70  71  72  73  74  75  76  78  81  82  84  85  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 105 106 107 108 112 113\n",
      " 114 115 116 118 119 120 122 123 124 126 127 128 130 131 132 133 134 135\n",
      " 136 137 140 141 142 143 144 145 146 147 148 150 151 153 154 155 157 158\n",
      " 159 160 162 163 164 165 167 168 169 170 171 172 173 174 175 176 177 178\n",
      " 179 180 181 183 185 186 187 188 190 191 192 194 195 196 197 198 199 200\n",
      " 201 202 203 205 206 207 208 209 210 211 213 218 219 220 221 222 224 225\n",
      " 227 229 230 231 232 233 235 236 238 239 240 241 242 243 244 245 246 247\n",
      " 249 250 252 253 254 255 256 257 261 262 263 264 265 268 270 271 272 273\n",
      " 276 277 278 279 281 282 283 284 285 288 289 290 291 292 293 295 297 298\n",
      " 299 301 302 303 304 305 306 308 310 311 312 313 314 315 316 318 319 320\n",
      " 321 322 324 325 329 330 332 333 334 335 336 337 338 339 340 341 342 343\n",
      " 344 345 346 347 348 349 350 351 353 354 355 356 357 358 359 361 362 364\n",
      " 365 366 367 368 369 370 372 373 375 377 378 379 380 381 382 383 384 385\n",
      " 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 403 405\n",
      " 406 408 409 411 412 413 414 415 416 417 418 419 420 421 423 424 425 426\n",
      " 427 428 429 430 431 432 433 434 436 437 439 440 441 442 444 448 451 452\n",
      " 453 454 457 458 459 461 463 464 465 466 467 468 469 471 472 473 474 477\n",
      " 478 479 480 481 482 484 486 487 488 489 490 491 492 493 494 499 500 501\n",
      " 502 503 504 505 506 508 509 510 511 512 514 515 516 517 518 519 520 521\n",
      " 522 523 525 526 527 528 529 530 531 532 534 536 537 538 539 540 542 543\n",
      " 544 545 546 547 548 549 550 551 553 554 555 557 558 559 560 561 562 563\n",
      " 564 565 566 567 568] TEST: [  3  11  13  16  19  24  25  27  29  32  36  40  41  58  67  77  79  80\n",
      "  83  86 104 109 110 111 117 121 125 129 138 139 149 152 156 161 166 182\n",
      " 184 189 193 204 212 214 215 216 217 223 226 228 234 237 248 251 258 259\n",
      " 260 266 267 269 274 275 280 286 287 294 296 300 307 309 317 323 326 327\n",
      " 328 331 352 360 363 371 374 376 402 404 407 410 422 435 438 443 445 446\n",
      " 447 449 450 455 456 460 462 470 475 476 483 485 495 496 497 498 507 513\n",
      " 524 533 535 541 552 556]\n",
      "TRAIN: [  1   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  24  25  26  27  29  30  31  32  33  34  35  36  37  38  39\n",
      "  40  41  44  45  46  49  51  52  54  55  56  58  59  60  61  63  64  65\n",
      "  66  67  68  71  73  74  75  76  77  78  79  80  81  83  85  86  88  89\n",
      "  90  92  93  96  97 100 101 102 103 104 105 106 107 108 109 110 111 112\n",
      " 113 114 116 117 118 120 121 122 124 125 126 127 129 132 133 134 135 136\n",
      " 137 138 139 140 141 142 144 145 146 149 150 152 153 154 155 156 157 158\n",
      " 159 160 161 162 164 165 166 167 168 170 171 172 173 175 176 179 181 182\n",
      " 184 185 186 188 189 190 191 193 194 195 196 198 199 200 202 204 205 206\n",
      " 208 210 211 212 213 214 215 216 217 218 219 220 221 223 224 225 226 228\n",
      " 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 245 246 247\n",
      " 248 249 250 251 252 253 254 255 258 259 260 261 262 263 264 266 267 268\n",
      " 269 271 272 274 275 276 278 280 281 282 283 284 285 286 287 289 290 293\n",
      " 294 295 296 297 298 299 300 301 302 303 306 307 308 309 310 311 312 313\n",
      " 315 316 317 318 319 320 322 323 325 326 327 328 329 330 331 332 333 334\n",
      " 336 337 338 339 340 342 343 344 345 346 347 348 350 351 352 353 354 355\n",
      " 356 357 358 360 361 362 363 364 365 366 367 371 372 374 375 376 378 379\n",
      " 380 381 382 384 385 386 389 390 391 392 393 395 399 400 401 402 403 404\n",
      " 406 407 408 409 410 412 413 414 415 416 417 420 421 422 424 425 426 427\n",
      " 428 429 432 433 434 435 436 437 438 439 440 441 443 444 445 446 447 449\n",
      " 450 452 453 454 455 456 457 458 460 462 463 464 465 466 467 468 469 470\n",
      " 471 473 474 475 476 477 478 479 481 482 483 484 485 487 489 490 491 492\n",
      " 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 512 513\n",
      " 514 515 516 517 518 519 520 523 524 525 526 527 530 531 532 533 534 535\n",
      " 538 539 541 542 545 546 547 548 549 550 552 553 554 555 556 557 560 561\n",
      " 562 563 564 565 566 567] TEST: [  0   9  23  28  42  43  47  48  50  53  57  62  69  70  72  82  84  87\n",
      "  91  94  95  98  99 115 119 123 128 130 131 143 147 148 151 163 169 174\n",
      " 177 178 180 183 187 192 197 201 203 207 209 222 227 244 256 257 265 270\n",
      " 273 277 279 288 291 292 304 305 314 321 324 335 341 349 359 368 369 370\n",
      " 373 377 383 387 388 394 396 397 398 405 411 418 419 423 430 431 442 448\n",
      " 451 459 461 472 480 486 488 509 510 511 521 522 528 529 536 537 540 543\n",
      " 544 551 558 559 568]\n"
     ]
    }
   ],
   "source": [
    "for train_index , test_index in kfold.split(breast_cancer.target):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    y_train , y_test = breast_cancer.target[train_index],breast_cancer.target[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_entropy = DecisionTreeClassifier(criterion='entropy',max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_pred = dec_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9734513274336283"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,dec_tree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_gini = DecisionTreeClassifier(criterion='gini',max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_gini.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_gini_pred = dec_tree_gini.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9557522123893806"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,dec_tree_gini_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "KN_classifer = KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KN_classifer.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "KN_classifer_pred = KN_classifer.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9469026548672567"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,KN_classifer_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_predict = svc_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9646017699115044"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,svc_model_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_rbf_kernel = SVC(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model_rbf_kernel.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_rbf_kernel_pred = svc_model_rbf_kernel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6194690265486725"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,svc_model_rbf_kernel_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boost_classifier = GradientBoostingClassifier(max_depth=15)#depth effects the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=15,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_boost_classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boost_classifier_pred = gradient_boost_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9734513274336283"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,gradient_boost_classifier_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifier=RandomForestClassifier(criterion='gini') # 97% with  entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifier_predict = random_forest_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9557522123893806"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,random_forest_classifier_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree_classifier = ExtraTreesClassifier(criterion='gini',max_depth=5) #97% with entropy also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "                     oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree_classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree_classifier_pred = extra_tree_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9734513274336283"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,extra_tree_classifier_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_nb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_nb_pred = gaussian_nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9646017699115044"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,gaussian_nb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train ,x_test,y_train,y_test = train_test_split(boston.data,boston.target,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_Reg_boston = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_Reg_boston.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_Reg_boston_predict=linear_Reg_boston.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.776607234871386"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_Reg_boston.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_Reg_boston.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_Reg_boston_predict=linear_Reg_boston.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.95331660532518"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_Reg_boston.score(X_test,Y_test) * 100 #with simple train test split accuracy is 77% but with kfold it is 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfoldd = KFold(n_splits=13,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  0   2   3   4   5   6   7   8   9  11  13  14  16  17  18  19  20  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  38  39  40  41\n",
      "  42  43  44  47  48  49  50  51  52  53  55  57  58  59  61  62  63  64\n",
      "  66  67  68  69  70  71  72  73  74  77  79  80  81  82  83  84  85  86\n",
      "  87  88  89  91  92  93  94  95  98  99 101 103 104 105 106 109 110 111\n",
      " 112 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130\n",
      " 131 132 133 135 136 138 139 140 141 142 143 145 146 147 148 149 150 151\n",
      " 152 156 157 158 160 161 163 164 165 166 167 168 169 170 172 174 176 177\n",
      " 178 179 180 181 182 183 184 185 186 187 189 190 191 192 193 194 195 197\n",
      " 198 199 200 201 202 203 204 207 208 209 211 212 214 215 216 217 218 220\n",
      " 221 222 223 226 227 228 231 232 234 235 236 237 238 240 242 243 244 245\n",
      " 248 249 250 251 252 255 256 257 258 259 260 261 262 263 264 265 266 267\n",
      " 268 269 270 271 272 273 274 275 276 277 279 280 281 282 283 284 285 286\n",
      " 287 288 289 290 291 292 294 295 296 298 301 302 304 305 306 307 308 309\n",
      " 311 312 313 314 315 316 317 318 321 322 323 324 325 327 328 332 333 334\n",
      " 335 336 337 338 339 341 343 345 347 348 349 350 351 353 354 355 356 357\n",
      " 358 359 360 361 362 364 365 366 368 369 370 373 375 376 377 378 379 380\n",
      " 381 382 383 384 385 388 389 390 392 393 394 395 396 397 398 399 401 402\n",
      " 404 405 406 408 412 413 414 415 416 417 419 420 421 422 423 424 425 427\n",
      " 428 429 431 432 433 434 436 437 438 439 440 441 442 443 444 445 447 448\n",
      " 449 450 452 453 454 456 457 458 460 461 462 463 464 465 466 467 468 470\n",
      " 471 472 473 476 477 479 482 483 484 485 486 488 489 490 491 492 493 494\n",
      " 496 498 499 500 501 502 503 504] TEST: [  1  10  12  15  21  37  45  46  54  56  60  65  75  76  78  90  96  97\n",
      " 100 102 107 108 113 134 137 144 153 154 155 159 162 171 173 175 188 196\n",
      " 205 206 210 213 219 224 225 229 230 233 239 241 246 247 253 254 278 293\n",
      " 297 299 300 303 310 319 320 326 329 330 331 340 342 344 346 352 363 367\n",
      " 371 372 374 386 387 391 400 403 407 409 410 411 418 426 430 435 446 451\n",
      " 455 459 469 474 475 478 480 481 487 495 497 505]\n",
      "TRAIN: [  0   1   2   3   9  10  11  12  13  15  16  17  19  21  23  24  25  27\n",
      "  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  50  53  54  56  57  58  60  61  62  65  66  67  69  70  72\n",
      "  73  75  76  77  78  79  80  82  83  84  85  86  87  88  90  91  94  95\n",
      "  96  97  98  99 100 101 102 103 104 105 107 108 109 110 111 112 113 114\n",
      " 115 116 117 119 120 121 123 125 126 127 128 129 130 131 133 134 136 137\n",
      " 138 139 140 143 144 145 146 147 148 149 150 151 152 153 154 155 156 158\n",
      " 159 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178 180\n",
      " 181 182 183 184 185 187 188 189 190 192 193 195 196 197 198 199 201 202\n",
      " 203 204 205 206 207 209 210 211 212 213 214 215 216 217 218 219 221 222\n",
      " 223 224 225 226 227 228 229 230 232 233 234 236 237 238 239 241 242 243\n",
      " 244 246 247 248 250 251 252 253 254 255 256 257 258 259 260 262 264 265\n",
      " 266 267 269 270 271 273 274 275 277 278 279 280 284 285 286 287 288 289\n",
      " 290 291 292 293 294 295 296 297 299 300 303 304 305 307 310 312 313 314\n",
      " 316 317 318 319 320 321 323 324 326 328 329 330 331 332 333 334 335 337\n",
      " 338 339 340 341 342 343 344 345 346 347 349 350 351 352 353 354 355 356\n",
      " 357 358 359 361 362 363 364 365 367 368 369 370 371 372 373 374 375 376\n",
      " 377 380 381 382 384 386 387 388 389 390 391 393 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 409 410 411 412 413 414 418 420 421 422 423 424\n",
      " 425 426 429 430 431 432 434 435 436 439 440 441 442 443 444 446 447 448\n",
      " 449 450 451 452 453 454 455 456 457 459 460 462 463 464 466 467 468 469\n",
      " 470 471 472 474 475 476 478 479 480 481 482 483 485 486 487 488 489 490\n",
      " 492 493 495 497 500 501 503 504 505] TEST: [  4   5   6   7   8  14  18  20  22  26  49  51  52  55  59  63  64  68\n",
      "  71  74  81  89  92  93 106 118 122 124 132 135 141 142 157 160 164 170\n",
      " 179 186 191 194 200 208 220 231 235 240 245 249 261 263 268 272 276 281\n",
      " 282 283 298 301 302 306 308 309 311 315 322 325 327 336 348 360 366 378\n",
      " 379 383 385 392 394 395 408 415 416 417 419 427 428 433 437 438 445 458\n",
      " 461 465 473 477 484 491 494 496 498 499 502]\n",
      "TRAIN: [  0   1   3   4   5   6   7   8   9  10  11  12  13  14  15  16  18  19\n",
      "  20  21  22  23  25  26  28  31  32  36  37  38  39  41  42  43  45  46\n",
      "  47  48  49  50  51  52  53  54  55  56  57  58  59  60  62  63  64  65\n",
      "  68  69  70  71  72  74  75  76  77  78  80  81  82  83  84  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 102 105 106 107 108 109\n",
      " 110 113 115 117 118 119 121 122 123 124 125 127 128 130 131 132 134 135\n",
      " 137 139 141 142 143 144 147 148 149 151 152 153 154 155 157 159 160 161\n",
      " 162 163 164 165 169 170 171 172 173 174 175 177 178 179 180 182 183 184\n",
      " 185 186 187 188 191 192 193 194 195 196 197 200 201 202 203 205 206 207\n",
      " 208 209 210 211 213 219 220 222 224 225 226 227 228 229 230 231 233 235\n",
      " 237 239 240 241 242 243 244 245 246 247 248 249 251 253 254 256 257 258\n",
      " 260 261 262 263 265 266 267 268 269 270 272 273 275 276 277 278 279 280\n",
      " 281 282 283 285 286 287 288 290 291 292 293 294 296 297 298 299 300 301\n",
      " 302 303 304 305 306 307 308 309 310 311 314 315 317 318 319 320 321 322\n",
      " 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 340 341\n",
      " 342 343 344 346 348 349 352 353 356 358 359 360 362 363 366 367 368 369\n",
      " 370 371 372 373 374 375 376 378 379 380 381 383 384 385 386 387 388 389\n",
      " 390 391 392 394 395 396 397 398 400 401 402 403 404 405 406 407 408 409\n",
      " 410 411 414 415 416 417 418 419 420 421 423 425 426 427 428 430 431 432\n",
      " 433 434 435 437 438 440 442 443 445 446 447 448 449 450 451 452 453 454\n",
      " 455 458 459 460 461 462 464 465 466 468 469 470 471 472 473 474 475 476\n",
      " 477 478 479 480 481 483 484 486 487 488 489 490 491 492 493 494 495 496\n",
      " 497 498 499 500 501 502 503 504 505] TEST: [  2  17  24  27  29  30  33  34  35  40  44  61  66  67  73  79  85 101\n",
      " 103 104 111 112 114 116 120 126 129 133 136 138 140 145 146 150 156 158\n",
      " 166 167 168 176 181 189 190 198 199 204 212 214 215 216 217 218 221 223\n",
      " 232 234 236 238 250 252 255 259 264 271 274 284 289 295 312 313 316 339\n",
      " 345 347 350 351 354 355 357 361 364 365 377 382 393 399 412 413 422 424\n",
      " 429 436 439 441 444 456 457 463 467 482 485]\n",
      "TRAIN: [  1   2   4   5   6   7   8   9  10  12  14  15  17  18  20  21  22  24\n",
      "  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40  42  44  45\n",
      "  46  47  49  51  52  53  54  55  56  57  59  60  61  63  64  65  66  67\n",
      "  68  70  71  72  73  74  75  76  78  79  81  82  84  85  87  88  89  90\n",
      "  91  92  93  96  97  99 100 101 102 103 104 105 106 107 108 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 124 126 127 128 129 131 132 133 134\n",
      " 135 136 137 138 140 141 142 144 145 146 147 150 151 153 154 155 156 157\n",
      " 158 159 160 162 163 164 165 166 167 168 170 171 172 173 174 175 176 177\n",
      " 179 180 181 183 185 186 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 202 203 204 205 206 208 210 211 212 213 214 215 216 217 218 219 220\n",
      " 221 223 224 225 229 230 231 232 233 234 235 236 238 239 240 241 242 243\n",
      " 244 245 246 247 249 250 251 252 253 254 255 257 259 261 262 263 264 265\n",
      " 267 268 271 272 273 274 276 277 278 281 282 283 284 285 288 289 290 291\n",
      " 292 293 295 297 298 299 300 301 302 303 306 308 309 310 311 312 313 314\n",
      " 315 316 319 320 321 322 323 324 325 326 327 329 330 331 333 335 336 337\n",
      " 338 339 340 342 344 345 346 347 348 350 351 352 354 355 356 357 358 359\n",
      " 360 361 363 364 365 366 367 370 371 372 374 376 377 378 379 382 383 384\n",
      " 385 386 387 388 389 391 392 393 394 395 396 398 399 400 403 404 407 408\n",
      " 409 410 411 412 413 415 416 417 418 419 420 422 423 424 425 426 427 428\n",
      " 429 430 431 433 435 436 437 438 439 440 441 443 444 445 446 448 449 450\n",
      " 451 452 454 455 456 457 458 459 460 461 462 463 464 465 466 467 469 470\n",
      " 472 473 474 475 476 477 478 480 481 482 484 485 487 488 489 490 491 492\n",
      " 494 495 496 497 498 499 502 504 505] TEST: [  0   3  11  13  16  19  23  36  41  43  48  50  58  62  69  77  80  83\n",
      "  86  94  95  98 109 110 123 125 130 139 143 148 149 152 161 169 178 182\n",
      " 184 187 201 207 209 222 226 227 228 237 248 256 258 260 266 269 270 275\n",
      " 279 280 286 287 294 296 304 305 307 317 318 328 332 334 341 343 349 353\n",
      " 362 368 369 373 375 380 381 390 397 401 402 405 406 414 421 432 434 442\n",
      " 447 453 468 471 479 483 486 493 500 501 503]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  26  27  29  30  33  34  35  36  37  40  41  43\n",
      "  44  45  46  48  49  50  51  52  54  55  56  58  59  60  61  62  63  64\n",
      "  65  66  67  68  69  71  73  74  75  76  77  78  79  80  81  83  85  86\n",
      "  89  90  92  93  94  95  96  97  98 100 101 102 103 104 106 107 108 109\n",
      " 110 111 112 113 114 116 118 120 122 123 124 125 126 129 130 132 133 134\n",
      " 135 136 137 138 139 140 141 142 143 144 145 146 148 149 150 152 153 154\n",
      " 155 156 157 158 159 160 161 162 164 166 167 168 169 170 171 173 175 176\n",
      " 178 179 181 182 184 186 187 188 189 190 191 194 196 198 199 200 201 204\n",
      " 205 206 207 208 209 210 212 213 214 215 216 217 218 219 220 221 222 223\n",
      " 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241\n",
      " 245 246 247 248 249 250 252 253 254 255 256 258 259 260 261 263 264 266\n",
      " 268 269 270 271 272 274 275 276 278 279 280 281 282 283 284 286 287 289\n",
      " 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310\n",
      " 311 312 313 315 316 317 318 319 320 322 325 326 327 328 329 330 331 332\n",
      " 334 336 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354\n",
      " 355 357 360 361 362 363 364 365 366 367 368 369 371 372 373 374 375 377\n",
      " 378 379 380 381 382 383 385 386 387 390 391 392 393 394 395 397 399 400\n",
      " 401 402 403 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 421 422 424 426 427 428 429 430 432 433 434 435 436 437 438 439 441 442\n",
      " 444 445 446 447 451 453 455 456 457 458 459 461 463 465 467 468 469 471\n",
      " 473 474 475 477 478 479 480 481 482 483 484 485 486 487 491 493 494 495\n",
      " 496 497 498 499 500 501 502 503 505] TEST: [  9  25  28  31  32  38  39  42  47  53  57  70  72  82  84  87  88  91\n",
      "  99 105 115 117 119 121 127 128 131 147 151 163 165 172 174 177 180 183\n",
      " 185 192 193 195 197 202 203 211 242 243 244 251 257 262 265 267 273 277\n",
      " 285 288 290 291 292 314 321 323 324 333 335 337 338 356 358 359 370 376\n",
      " 384 388 389 396 398 404 420 423 425 431 440 443 448 449 450 452 454 460\n",
      " 462 464 466 470 472 476 488 489 490 492 504]\n"
     ]
    }
   ],
   "source": [
    "for train_index , test_index in kfold.split(boston.data):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train ,X_test  = boston.data[train_index] ,boston.data[test_index]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  0   2   3   4   5   6   7   8   9  11  13  14  16  17  18  19  20  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  38  39  40  41\n",
      "  42  43  44  47  48  49  50  51  52  53  55  57  58  59  61  62  63  64\n",
      "  66  67  68  69  70  71  72  73  74  77  79  80  81  82  83  84  85  86\n",
      "  87  88  89  91  92  93  94  95  98  99 101 103 104 105 106 109 110 111\n",
      " 112 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130\n",
      " 131 132 133 135 136 138 139 140 141 142 143 145 146 147 148 149 150 151\n",
      " 152 156 157 158 160 161 163 164 165 166 167 168 169 170 172 174 176 177\n",
      " 178 179 180 181 182 183 184 185 186 187 189 190 191 192 193 194 195 197\n",
      " 198 199 200 201 202 203 204 207 208 209 211 212 214 215 216 217 218 220\n",
      " 221 222 223 226 227 228 231 232 234 235 236 237 238 240 242 243 244 245\n",
      " 248 249 250 251 252 255 256 257 258 259 260 261 262 263 264 265 266 267\n",
      " 268 269 270 271 272 273 274 275 276 277 279 280 281 282 283 284 285 286\n",
      " 287 288 289 290 291 292 294 295 296 298 301 302 304 305 306 307 308 309\n",
      " 311 312 313 314 315 316 317 318 321 322 323 324 325 327 328 332 333 334\n",
      " 335 336 337 338 339 341 343 345 347 348 349 350 351 353 354 355 356 357\n",
      " 358 359 360 361 362 364 365 366 368 369 370 373 375 376 377 378 379 380\n",
      " 381 382 383 384 385 388 389 390 392 393 394 395 396 397 398 399 401 402\n",
      " 404 405 406 408 412 413 414 415 416 417 419 420 421 422 423 424 425 427\n",
      " 428 429 431 432 433 434 436 437 438 439 440 441 442 443 444 445 447 448\n",
      " 449 450 452 453 454 456 457 458 460 461 462 463 464 465 466 467 468 470\n",
      " 471 472 473 476 477 479 482 483 484 485 486 488 489 490 491 492 493 494\n",
      " 496 498 499 500 501 502 503 504] TEST: [  1  10  12  15  21  37  45  46  54  56  60  65  75  76  78  90  96  97\n",
      " 100 102 107 108 113 134 137 144 153 154 155 159 162 171 173 175 188 196\n",
      " 205 206 210 213 219 224 225 229 230 233 239 241 246 247 253 254 278 293\n",
      " 297 299 300 303 310 319 320 326 329 330 331 340 342 344 346 352 363 367\n",
      " 371 372 374 386 387 391 400 403 407 409 410 411 418 426 430 435 446 451\n",
      " 455 459 469 474 475 478 480 481 487 495 497 505]\n",
      "TRAIN: [  0   1   2   3   9  10  11  12  13  15  16  17  19  21  23  24  25  27\n",
      "  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  50  53  54  56  57  58  60  61  62  65  66  67  69  70  72\n",
      "  73  75  76  77  78  79  80  82  83  84  85  86  87  88  90  91  94  95\n",
      "  96  97  98  99 100 101 102 103 104 105 107 108 109 110 111 112 113 114\n",
      " 115 116 117 119 120 121 123 125 126 127 128 129 130 131 133 134 136 137\n",
      " 138 139 140 143 144 145 146 147 148 149 150 151 152 153 154 155 156 158\n",
      " 159 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178 180\n",
      " 181 182 183 184 185 187 188 189 190 192 193 195 196 197 198 199 201 202\n",
      " 203 204 205 206 207 209 210 211 212 213 214 215 216 217 218 219 221 222\n",
      " 223 224 225 226 227 228 229 230 232 233 234 236 237 238 239 241 242 243\n",
      " 244 246 247 248 250 251 252 253 254 255 256 257 258 259 260 262 264 265\n",
      " 266 267 269 270 271 273 274 275 277 278 279 280 284 285 286 287 288 289\n",
      " 290 291 292 293 294 295 296 297 299 300 303 304 305 307 310 312 313 314\n",
      " 316 317 318 319 320 321 323 324 326 328 329 330 331 332 333 334 335 337\n",
      " 338 339 340 341 342 343 344 345 346 347 349 350 351 352 353 354 355 356\n",
      " 357 358 359 361 362 363 364 365 367 368 369 370 371 372 373 374 375 376\n",
      " 377 380 381 382 384 386 387 388 389 390 391 393 396 397 398 399 400 401\n",
      " 402 403 404 405 406 407 409 410 411 412 413 414 418 420 421 422 423 424\n",
      " 425 426 429 430 431 432 434 435 436 439 440 441 442 443 444 446 447 448\n",
      " 449 450 451 452 453 454 455 456 457 459 460 462 463 464 466 467 468 469\n",
      " 470 471 472 474 475 476 478 479 480 481 482 483 485 486 487 488 489 490\n",
      " 492 493 495 497 500 501 503 504 505] TEST: [  4   5   6   7   8  14  18  20  22  26  49  51  52  55  59  63  64  68\n",
      "  71  74  81  89  92  93 106 118 122 124 132 135 141 142 157 160 164 170\n",
      " 179 186 191 194 200 208 220 231 235 240 245 249 261 263 268 272 276 281\n",
      " 282 283 298 301 302 306 308 309 311 315 322 325 327 336 348 360 366 378\n",
      " 379 383 385 392 394 395 408 415 416 417 419 427 428 433 437 438 445 458\n",
      " 461 465 473 477 484 491 494 496 498 499 502]\n",
      "TRAIN: [  0   1   3   4   5   6   7   8   9  10  11  12  13  14  15  16  18  19\n",
      "  20  21  22  23  25  26  28  31  32  36  37  38  39  41  42  43  45  46\n",
      "  47  48  49  50  51  52  53  54  55  56  57  58  59  60  62  63  64  65\n",
      "  68  69  70  71  72  74  75  76  77  78  80  81  82  83  84  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 102 105 106 107 108 109\n",
      " 110 113 115 117 118 119 121 122 123 124 125 127 128 130 131 132 134 135\n",
      " 137 139 141 142 143 144 147 148 149 151 152 153 154 155 157 159 160 161\n",
      " 162 163 164 165 169 170 171 172 173 174 175 177 178 179 180 182 183 184\n",
      " 185 186 187 188 191 192 193 194 195 196 197 200 201 202 203 205 206 207\n",
      " 208 209 210 211 213 219 220 222 224 225 226 227 228 229 230 231 233 235\n",
      " 237 239 240 241 242 243 244 245 246 247 248 249 251 253 254 256 257 258\n",
      " 260 261 262 263 265 266 267 268 269 270 272 273 275 276 277 278 279 280\n",
      " 281 282 283 285 286 287 288 290 291 292 293 294 296 297 298 299 300 301\n",
      " 302 303 304 305 306 307 308 309 310 311 314 315 317 318 319 320 321 322\n",
      " 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 340 341\n",
      " 342 343 344 346 348 349 352 353 356 358 359 360 362 363 366 367 368 369\n",
      " 370 371 372 373 374 375 376 378 379 380 381 383 384 385 386 387 388 389\n",
      " 390 391 392 394 395 396 397 398 400 401 402 403 404 405 406 407 408 409\n",
      " 410 411 414 415 416 417 418 419 420 421 423 425 426 427 428 430 431 432\n",
      " 433 434 435 437 438 440 442 443 445 446 447 448 449 450 451 452 453 454\n",
      " 455 458 459 460 461 462 464 465 466 468 469 470 471 472 473 474 475 476\n",
      " 477 478 479 480 481 483 484 486 487 488 489 490 491 492 493 494 495 496\n",
      " 497 498 499 500 501 502 503 504 505] TEST: [  2  17  24  27  29  30  33  34  35  40  44  61  66  67  73  79  85 101\n",
      " 103 104 111 112 114 116 120 126 129 133 136 138 140 145 146 150 156 158\n",
      " 166 167 168 176 181 189 190 198 199 204 212 214 215 216 217 218 221 223\n",
      " 232 234 236 238 250 252 255 259 264 271 274 284 289 295 312 313 316 339\n",
      " 345 347 350 351 354 355 357 361 364 365 377 382 393 399 412 413 422 424\n",
      " 429 436 439 441 444 456 457 463 467 482 485]\n",
      "TRAIN: [  1   2   4   5   6   7   8   9  10  12  14  15  17  18  20  21  22  24\n",
      "  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40  42  44  45\n",
      "  46  47  49  51  52  53  54  55  56  57  59  60  61  63  64  65  66  67\n",
      "  68  70  71  72  73  74  75  76  78  79  81  82  84  85  87  88  89  90\n",
      "  91  92  93  96  97  99 100 101 102 103 104 105 106 107 108 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 124 126 127 128 129 131 132 133 134\n",
      " 135 136 137 138 140 141 142 144 145 146 147 150 151 153 154 155 156 157\n",
      " 158 159 160 162 163 164 165 166 167 168 170 171 172 173 174 175 176 177\n",
      " 179 180 181 183 185 186 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 202 203 204 205 206 208 210 211 212 213 214 215 216 217 218 219 220\n",
      " 221 223 224 225 229 230 231 232 233 234 235 236 238 239 240 241 242 243\n",
      " 244 245 246 247 249 250 251 252 253 254 255 257 259 261 262 263 264 265\n",
      " 267 268 271 272 273 274 276 277 278 281 282 283 284 285 288 289 290 291\n",
      " 292 293 295 297 298 299 300 301 302 303 306 308 309 310 311 312 313 314\n",
      " 315 316 319 320 321 322 323 324 325 326 327 329 330 331 333 335 336 337\n",
      " 338 339 340 342 344 345 346 347 348 350 351 352 354 355 356 357 358 359\n",
      " 360 361 363 364 365 366 367 370 371 372 374 376 377 378 379 382 383 384\n",
      " 385 386 387 388 389 391 392 393 394 395 396 398 399 400 403 404 407 408\n",
      " 409 410 411 412 413 415 416 417 418 419 420 422 423 424 425 426 427 428\n",
      " 429 430 431 433 435 436 437 438 439 440 441 443 444 445 446 448 449 450\n",
      " 451 452 454 455 456 457 458 459 460 461 462 463 464 465 466 467 469 470\n",
      " 472 473 474 475 476 477 478 480 481 482 484 485 487 488 489 490 491 492\n",
      " 494 495 496 497 498 499 502 504 505] TEST: [  0   3  11  13  16  19  23  36  41  43  48  50  58  62  69  77  80  83\n",
      "  86  94  95  98 109 110 123 125 130 139 143 148 149 152 161 169 178 182\n",
      " 184 187 201 207 209 222 226 227 228 237 248 256 258 260 266 269 270 275\n",
      " 279 280 286 287 294 296 304 305 307 317 318 328 332 334 341 343 349 353\n",
      " 362 368 369 373 375 380 381 390 397 401 402 405 406 414 421 432 434 442\n",
      " 447 453 468 471 479 483 486 493 500 501 503]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  26  27  29  30  33  34  35  36  37  40  41  43\n",
      "  44  45  46  48  49  50  51  52  54  55  56  58  59  60  61  62  63  64\n",
      "  65  66  67  68  69  71  73  74  75  76  77  78  79  80  81  83  85  86\n",
      "  89  90  92  93  94  95  96  97  98 100 101 102 103 104 106 107 108 109\n",
      " 110 111 112 113 114 116 118 120 122 123 124 125 126 129 130 132 133 134\n",
      " 135 136 137 138 139 140 141 142 143 144 145 146 148 149 150 152 153 154\n",
      " 155 156 157 158 159 160 161 162 164 166 167 168 169 170 171 173 175 176\n",
      " 178 179 181 182 184 186 187 188 189 190 191 194 196 198 199 200 201 204\n",
      " 205 206 207 208 209 210 212 213 214 215 216 217 218 219 220 221 222 223\n",
      " 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241\n",
      " 245 246 247 248 249 250 252 253 254 255 256 258 259 260 261 263 264 266\n",
      " 268 269 270 271 272 274 275 276 278 279 280 281 282 283 284 286 287 289\n",
      " 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310\n",
      " 311 312 313 315 316 317 318 319 320 322 325 326 327 328 329 330 331 332\n",
      " 334 336 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354\n",
      " 355 357 360 361 362 363 364 365 366 367 368 369 371 372 373 374 375 377\n",
      " 378 379 380 381 382 383 385 386 387 390 391 392 393 394 395 397 399 400\n",
      " 401 402 403 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419\n",
      " 421 422 424 426 427 428 429 430 432 433 434 435 436 437 438 439 441 442\n",
      " 444 445 446 447 451 453 455 456 457 458 459 461 463 465 467 468 469 471\n",
      " 473 474 475 477 478 479 480 481 482 483 484 485 486 487 491 493 494 495\n",
      " 496 497 498 499 500 501 502 503 505] TEST: [  9  25  28  31  32  38  39  42  47  53  57  70  72  82  84  87  88  91\n",
      "  99 105 115 117 119 121 127 128 131 147 151 163 165 172 174 177 180 183\n",
      " 185 192 193 195 197 202 203 211 242 243 244 251 257 262 265 267 273 277\n",
      " 285 288 290 291 292 314 321 323 324 333 335 337 338 356 358 359 370 376\n",
      " 384 388 389 396 398 404 420 423 425 431 440 443 448 449 450 452 454 460\n",
      " 462 464 466 470 472 476 488 489 490 492 504]\n"
     ]
    }
   ],
   "source": [
    "for train_index , test_index in kfold.split(boston.target):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Y_train ,Y_test  = boston.target[train_index] ,boston.target[test_index]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "KN_regressor_boston = KNeighborsRegressor(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KN_regressor_boston.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "KN_regressor_boston_pred =KN_regressor_boston.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6711438939233842"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KN_regressor_boston.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KN_regressor_boston.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "KN_regressor_boston_pred =KN_regressor_boston.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6621262458471762"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KN_regressor_boston.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_regressor_boston = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_regressor_boston.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_regressor_boston_pred = dec_tree_regressor_boston.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8566197998971605"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_regressor_boston.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree_regressor_boston = ExtraTreesRegressor(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=10,\n",
       "                    max_features='auto', max_leaf_nodes=None,\n",
       "                    min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                    min_samples_leaf=1, min_samples_split=2,\n",
       "                    min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "                    oob_score=False, random_state=None, verbose=0,\n",
       "                    warm_start=False)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree_regressor_boston.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree_regressor_boston_pred = extra_tree_regressor_boston.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9179798059408082"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree_regressor_boston.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree_regressor_boston_OutKfold = ExtraTreesRegressor(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=10,\n",
       "                    max_features='auto', max_leaf_nodes=None,\n",
       "                    min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                    min_samples_leaf=1, min_samples_split=2,\n",
       "                    min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "                    oob_score=False, random_state=None, verbose=0,\n",
       "                    warm_start=False)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree_regressor_boston_OutKfold.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree_regressor_boston_OutKfold_pred = extra_tree_regressor_boston_OutKfold.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9200331397232204"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree_regressor_boston_OutKfold.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_bost_reg_boston = GradientBoostingRegressor(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=10,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_bost_reg_boston.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_bost_reg_boston_pred = gradient_bost_reg_boston.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8915300478776318"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_bost_reg_boston.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_bost_reg_boston_outKfold = GradientBoostingRegressor(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=10,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_bost_reg_boston_outKfold.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_bost_reg_boston_outKfold_pred = gradient_bost_reg_boston_outKfold.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8712097476199874"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_bost_reg_boston_outKfold.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_for_reg_boston = RandomForestRegressor(max_depth=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_for_reg_boston.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_for_reg_boston_pred = random_for_reg_boston.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8848939766215236"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_for_reg_boston.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_for_reg_boston_outKfold = RandomForestRegressor(max_depth=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_for_reg_boston_outKfold.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_for_reg_boston_outKfold_pred = random_for_reg_boston_outKfold.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8866229922756153"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_for_reg_boston_outKfold.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_reg_boston = SVR(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "    gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_reg_boston.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_reg_boston_pred = svm_reg_boston.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8197055490769755"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_reg_boston.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_reg_boston_outKfold = SVR(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "    gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_reg_boston_outKfold.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_reg_boston_outKfold_pred = svm_reg_boston_outKfold.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0496444318246867"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_reg_boston_outKfold.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abalon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Sex','Length','Diameter','Height','Whole Weight','Shucked Weight','Viscera Weight','Shell Weight','Ring']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('abalone.data',names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole Weight</th>\n",
       "      <th>Shucked Weight</th>\n",
       "      <th>Viscera Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "      <th>Ring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole Weight  Shucked Weight  Viscera Weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell Weight  Ring  \n",
       "0         0.150    15  \n",
       "1         0.070     7  \n",
       "2         0.210     9  \n",
       "3         0.155    10  \n",
       "4         0.055     7  "
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f14885c4d10>"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.scatterplot(x='Length',y='Ring',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole Weight</th>\n",
       "      <th>Shucked Weight</th>\n",
       "      <th>Viscera Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "      <th>Ring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986812</td>\n",
       "      <td>0.827554</td>\n",
       "      <td>0.925261</td>\n",
       "      <td>0.897914</td>\n",
       "      <td>0.903018</td>\n",
       "      <td>0.897706</td>\n",
       "      <td>0.556720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diameter</th>\n",
       "      <td>0.986812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833684</td>\n",
       "      <td>0.925452</td>\n",
       "      <td>0.893162</td>\n",
       "      <td>0.899724</td>\n",
       "      <td>0.905330</td>\n",
       "      <td>0.574660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>0.827554</td>\n",
       "      <td>0.833684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819221</td>\n",
       "      <td>0.774972</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>0.817338</td>\n",
       "      <td>0.557467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whole Weight</th>\n",
       "      <td>0.925261</td>\n",
       "      <td>0.925452</td>\n",
       "      <td>0.819221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969405</td>\n",
       "      <td>0.966375</td>\n",
       "      <td>0.955355</td>\n",
       "      <td>0.540390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shucked Weight</th>\n",
       "      <td>0.897914</td>\n",
       "      <td>0.893162</td>\n",
       "      <td>0.774972</td>\n",
       "      <td>0.969405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931961</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>0.420884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viscera Weight</th>\n",
       "      <td>0.903018</td>\n",
       "      <td>0.899724</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>0.966375</td>\n",
       "      <td>0.931961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907656</td>\n",
       "      <td>0.503819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shell Weight</th>\n",
       "      <td>0.897706</td>\n",
       "      <td>0.905330</td>\n",
       "      <td>0.817338</td>\n",
       "      <td>0.955355</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>0.907656</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ring</th>\n",
       "      <td>0.556720</td>\n",
       "      <td>0.574660</td>\n",
       "      <td>0.557467</td>\n",
       "      <td>0.540390</td>\n",
       "      <td>0.420884</td>\n",
       "      <td>0.503819</td>\n",
       "      <td>0.627574</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Length  Diameter    Height  Whole Weight  Shucked Weight  \\\n",
       "Length          1.000000  0.986812  0.827554      0.925261        0.897914   \n",
       "Diameter        0.986812  1.000000  0.833684      0.925452        0.893162   \n",
       "Height          0.827554  0.833684  1.000000      0.819221        0.774972   \n",
       "Whole Weight    0.925261  0.925452  0.819221      1.000000        0.969405   \n",
       "Shucked Weight  0.897914  0.893162  0.774972      0.969405        1.000000   \n",
       "Viscera Weight  0.903018  0.899724  0.798319      0.966375        0.931961   \n",
       "Shell Weight    0.897706  0.905330  0.817338      0.955355        0.882617   \n",
       "Ring            0.556720  0.574660  0.557467      0.540390        0.420884   \n",
       "\n",
       "                Viscera Weight  Shell Weight      Ring  \n",
       "Length                0.903018      0.897706  0.556720  \n",
       "Diameter              0.899724      0.905330  0.574660  \n",
       "Height                0.798319      0.817338  0.557467  \n",
       "Whole Weight          0.966375      0.955355  0.540390  \n",
       "Shucked Weight        0.931961      0.882617  0.420884  \n",
       "Viscera Weight        1.000000      0.907656  0.503819  \n",
       "Shell Weight          0.907656      1.000000  0.627574  \n",
       "Ring                  0.503819      0.627574  1.000000  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole Weight</th>\n",
       "      <th>Shucked Weight</th>\n",
       "      <th>Viscera Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole Weight  Shucked Weight  Viscera Weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell Weight  \n",
       "0         0.150  \n",
       "1         0.070  \n",
       "2         0.210  \n",
       "3         0.155  \n",
       "4         0.055  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.loc[836]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_abalon= LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model_abalon.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_abalon_pred = linear_model_abalon.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5495081256910634"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model_abalon.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "KN_regressor_abalon = KNeighborsRegressor(n_neighbors=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=40, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KN_regressor_abalon.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "KN_regressor_abalon_pred = KN_regressor_abalon.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5837935321410133"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KN_regressor_abalon.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_regressor_abalon = DecisionTreeRegressor(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_regressor_abalon.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_regressor_abalon_pred = decision_regressor_abalon.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4481978535557713"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_regressor_abalon.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfoldd = KFold(n_splits=13,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    2    3 ... 4173 4174 4175] TEST: [   1    4   10   14   17   22   23   30   31   33   34   39   42   45\n",
      "   49   57   61   70   72   85   87   88   92  104  117  118  124  134\n",
      "  138  142  148  154  156  170  173  182  185  189  192  195  196  202\n",
      "  214  217  223  224  226  227  229  242  245  248  253  257  276  285\n",
      "  286  289  290  295  296  298  302  304  306  308  311  322  326  333\n",
      "  346  347  352  378  381  398  402  405  408  410  415  418  436  443\n",
      "  444  452  453  457  463  465  467  473  480  481  482  483  485  489\n",
      "  491  496  499  500  501  502  514  517  520  521  526  527  528  530\n",
      "  531  533  534  536  538  541  543  545  546  548  555  558  562  566\n",
      "  567  569  570  572  575  576  578  581  582  587  598  599  615  621\n",
      "  629  634  635  638  639  641  643  651  661  663  666  668  675  678\n",
      "  682  683  684  685  690  692  704  706  712  716  727  735  748  751\n",
      "  768  773  775  776  799  803  817  825  829  836  840  841  842  861\n",
      "  866  867  868  882  888  891  895  898  900  905  910  914  917  927\n",
      "  935  938  944  949  958  961  962  971  977  979  982  983  991  996\n",
      "  998 1001 1002 1005 1009 1012 1018 1021 1042 1043 1059 1062 1065 1068\n",
      " 1069 1073 1077 1082 1084 1087 1093 1095 1098 1109 1114 1115 1116 1118\n",
      " 1119 1120 1129 1161 1170 1180 1191 1195 1230 1235 1236 1239 1245 1248\n",
      " 1259 1262 1267 1270 1273 1275 1276 1277 1282 1285 1288 1292 1303 1313\n",
      " 1319 1326 1328 1329 1330 1332 1334 1336 1341 1343 1347 1349 1362 1363\n",
      " 1364 1366 1379 1380 1385 1399 1410 1412 1423 1430 1431 1432 1436 1446\n",
      " 1450 1457 1460 1465 1471 1474 1475 1489 1490 1491 1493 1495 1496 1499\n",
      " 1501 1505 1507 1509 1511 1523 1526 1533 1536 1553 1559 1567 1571 1572\n",
      " 1577 1580 1581 1583 1586 1601 1602 1618 1621 1633 1643 1651 1652 1654\n",
      " 1658 1662 1670 1675 1680 1687 1691 1692 1699 1703 1710 1721 1738 1746\n",
      " 1751 1754 1762 1767 1768 1770 1772 1774 1775 1783 1804 1808 1813 1818\n",
      " 1825 1830 1831 1835 1836 1837 1850 1852 1853 1869 1875 1881 1886 1887\n",
      " 1888 1892 1895 1900 1905 1906 1907 1920 1927 1928 1931 1936 1943 1947\n",
      " 1950 1953 1957 1965 1976 1979 1982 1990 1991 1992 2004 2012 2017 2031\n",
      " 2036 2044 2052 2054 2058 2062 2065 2067 2072 2078 2101 2102 2115 2137\n",
      " 2140 2148 2161 2164 2166 2172 2178 2180 2181 2188 2189 2193 2194 2198\n",
      " 2203 2204 2205 2211 2215 2219 2224 2226 2231 2232 2243 2244 2249 2250\n",
      " 2252 2258 2268 2275 2278 2284 2288 2294 2297 2299 2307 2310 2324 2330\n",
      " 2337 2343 2346 2348 2361 2362 2367 2377 2381 2404 2406 2409 2410 2427\n",
      " 2429 2430 2434 2439 2445 2447 2459 2460 2465 2470 2475 2482 2483 2484\n",
      " 2486 2497 2507 2527 2531 2533 2537 2545 2553 2559 2567 2574 2578 2583\n",
      " 2584 2586 2587 2592 2601 2615 2619 2621 2625 2627 2628 2635 2640 2644\n",
      " 2645 2651 2653 2655 2656 2663 2666 2678 2680 2702 2703 2704 2705 2709\n",
      " 2713 2715 2718 2719 2727 2729 2736 2743 2751 2756 2769 2781 2788 2793\n",
      " 2794 2796 2803 2804 2806 2815 2817 2821 2829 2846 2848 2855 2856 2859\n",
      " 2868 2873 2875 2876 2891 2898 2901 2905 2906 2914 2923 2928 2943 2946\n",
      " 2949 2950 2954 2962 2968 2972 2976 2980 2984 3001 3005 3009 3022 3025\n",
      " 3031 3032 3036 3038 3040 3049 3051 3055 3062 3063 3065 3066 3068 3075\n",
      " 3081 3086 3088 3092 3100 3106 3111 3117 3118 3120 3121 3126 3142 3145\n",
      " 3151 3155 3157 3160 3163 3176 3178 3185 3193 3194 3199 3211 3217 3222\n",
      " 3228 3229 3231 3236 3237 3239 3241 3242 3244 3247 3248 3265 3271 3272\n",
      " 3286 3287 3295 3297 3304 3305 3314 3316 3319 3326 3328 3346 3347 3351\n",
      " 3357 3359 3364 3366 3368 3371 3373 3378 3379 3388 3399 3402 3410 3420\n",
      " 3422 3428 3429 3434 3442 3449 3464 3469 3472 3475 3479 3487 3488 3492\n",
      " 3493 3494 3496 3497 3499 3501 3502 3507 3508 3514 3519 3524 3526 3528\n",
      " 3530 3539 3540 3541 3543 3544 3546 3551 3552 3553 3555 3556 3558 3564\n",
      " 3567 3578 3594 3595 3605 3610 3614 3617 3620 3628 3632 3640 3653 3654\n",
      " 3657 3686 3693 3703 3706 3716 3720 3722 3727 3730 3733 3735 3741 3752\n",
      " 3759 3764 3766 3772 3774 3784 3787 3795 3803 3812 3823 3825 3827 3830\n",
      " 3836 3841 3842 3844 3851 3857 3858 3859 3865 3870 3873 3877 3881 3896\n",
      " 3899 3902 3908 3909 3917 3924 3943 3949 3954 3956 3958 3966 3968 3971\n",
      " 3972 3979 3980 3981 3983 3987 3988 3990 3992 3993 3997 4000 4011 4014\n",
      " 4016 4020 4021 4022 4032 4035 4036 4039 4040 4041 4043 4062 4064 4066\n",
      " 4070 4072 4083 4092 4093 4102 4119 4120 4122 4124 4125 4126 4131 4133\n",
      " 4135 4144 4153 4154 4160 4161 4164 4167 4172 4176]\n",
      "TRAIN: [   0    1    3 ... 4174 4175 4176] TEST: [   2    5    9   11   15   27   29   36   37   40   44   50   53   64\n",
      "   66   69   71   76   82   97   98  109  113  119  121  122  132  133\n",
      "  135  137  141  149  158  159  161  169  175  177  179  188  191  200\n",
      "  206  211  215  218  219  228  234  235  240  249  252  259  263  264\n",
      "  269  271  272  277  283  299  300  305  314  316  317  320  330  332\n",
      "  338  349  351  353  361  366  368  369  376  380  383  385  386  388\n",
      "  392  394  396  399  406  411  413  414  422  425  427  446  454  456\n",
      "  458  461  472  476  478  488  493  503  507  516  519  529  547  553\n",
      "  559  563  564  565  579  589  590  596  597  600  601  616  618  619\n",
      "  620  628  648  652  654  655  657  670  672  674  677  686  687  688\n",
      "  700  701  702  710  711  713  719  720  722  723  725  728  743  744\n",
      "  745  746  752  758  762  764  778  779  783  788  789  791  793  794\n",
      "  796  805  806  820  826  831  832  835  846  847  849  850  852  856\n",
      "  862  864  871  874  879  880  883  886  890  896  899  909  913  918\n",
      "  921  923  924  934  936  939  940  942  951  953  954  955  964  965\n",
      "  969  972  976  981  984  988  989  995  999 1003 1013 1014 1015 1023\n",
      " 1027 1032 1036 1037 1038 1044 1047 1051 1052 1061 1070 1078 1094 1100\n",
      " 1101 1108 1110 1122 1127 1128 1137 1139 1140 1148 1150 1151 1157 1160\n",
      " 1171 1174 1182 1184 1185 1196 1197 1199 1203 1212 1220 1223 1225 1232\n",
      " 1237 1240 1242 1246 1254 1256 1261 1266 1268 1269 1271 1280 1281 1283\n",
      " 1284 1287 1290 1299 1300 1310 1311 1317 1318 1324 1327 1338 1351 1355\n",
      " 1357 1358 1359 1367 1368 1370 1371 1373 1376 1377 1382 1386 1387 1388\n",
      " 1390 1393 1396 1397 1411 1414 1418 1420 1422 1424 1427 1428 1448 1451\n",
      " 1458 1462 1464 1473 1478 1487 1494 1503 1504 1513 1515 1519 1521 1525\n",
      " 1530 1535 1540 1544 1547 1548 1555 1560 1564 1569 1587 1590 1593 1606\n",
      " 1615 1625 1632 1642 1644 1646 1647 1649 1657 1666 1669 1695 1697 1698\n",
      " 1702 1708 1712 1713 1715 1728 1732 1733 1736 1739 1742 1752 1757 1759\n",
      " 1760 1761 1763 1764 1765 1766 1778 1791 1793 1794 1811 1815 1824 1826\n",
      " 1832 1839 1855 1856 1865 1867 1872 1877 1878 1898 1902 1912 1914 1916\n",
      " 1917 1923 1939 1940 1944 1945 1948 1949 1951 1952 1955 1958 1962 1969\n",
      " 1972 1974 1983 1997 2013 2019 2024 2025 2027 2030 2033 2034 2038 2039\n",
      " 2041 2047 2048 2049 2057 2063 2070 2074 2075 2087 2088 2095 2096 2100\n",
      " 2103 2104 2106 2112 2118 2123 2124 2125 2126 2131 2134 2142 2143 2151\n",
      " 2155 2160 2162 2165 2174 2183 2200 2201 2210 2213 2216 2223 2230 2240\n",
      " 2254 2255 2263 2265 2270 2271 2272 2285 2287 2293 2300 2301 2306 2308\n",
      " 2315 2318 2319 2323 2327 2329 2331 2340 2342 2347 2350 2351 2357 2359\n",
      " 2372 2374 2378 2379 2383 2385 2390 2399 2407 2408 2415 2420 2423 2436\n",
      " 2443 2452 2453 2455 2462 2466 2468 2472 2473 2476 2478 2481 2487 2500\n",
      " 2509 2513 2523 2525 2526 2530 2534 2540 2542 2543 2549 2554 2560 2563\n",
      " 2569 2588 2591 2597 2600 2602 2604 2620 2622 2629 2630 2631 2638 2657\n",
      " 2669 2675 2677 2682 2688 2689 2692 2697 2698 2700 2707 2708 2714 2717\n",
      " 2722 2724 2730 2735 2755 2759 2760 2765 2768 2773 2777 2779 2780 2795\n",
      " 2801 2810 2823 2824 2833 2842 2843 2853 2858 2861 2864 2866 2872 2886\n",
      " 2889 2895 2896 2911 2917 2931 2944 2947 2948 2951 2970 2981 2990 2994\n",
      " 2996 3003 3014 3020 3034 3039 3045 3053 3069 3070 3076 3080 3082 3084\n",
      " 3087 3094 3099 3101 3119 3135 3136 3138 3141 3144 3149 3154 3159 3162\n",
      " 3167 3169 3170 3171 3173 3175 3182 3184 3201 3202 3206 3209 3212 3232\n",
      " 3234 3249 3260 3266 3267 3269 3285 3293 3294 3296 3307 3311 3312 3313\n",
      " 3321 3327 3335 3339 3340 3349 3352 3353 3363 3365 3375 3377 3382 3383\n",
      " 3384 3387 3389 3391 3401 3403 3405 3409 3411 3424 3427 3431 3433 3439\n",
      " 3446 3461 3473 3478 3480 3481 3489 3495 3503 3509 3515 3517 3518 3521\n",
      " 3527 3529 3536 3537 3549 3559 3562 3563 3565 3569 3574 3576 3585 3593\n",
      " 3599 3601 3627 3633 3643 3645 3655 3658 3660 3662 3667 3672 3681 3682\n",
      " 3688 3689 3691 3702 3704 3714 3715 3723 3725 3728 3732 3737 3739 3743\n",
      " 3745 3750 3751 3756 3757 3758 3765 3767 3770 3773 3783 3785 3793 3805\n",
      " 3809 3810 3811 3813 3824 3828 3829 3833 3839 3845 3855 3860 3862 3863\n",
      " 3875 3887 3889 3892 3895 3903 3905 3915 3916 3920 3932 3934 3935 3945\n",
      " 3946 3955 3962 3967 3970 3978 3989 3991 4008 4018 4025 4027 4029 4031\n",
      " 4046 4053 4054 4057 4063 4068 4074 4085 4087 4088 4090 4091 4095 4100\n",
      " 4110 4113 4117 4129 4130 4137 4141 4142 4163 4170]\n",
      "TRAIN: [   0    1    2 ... 4174 4175 4176] TEST: [   6    8   13   18   19   20   38   41   43   47   48   52   54   55\n",
      "   58   59   68   77   80   84   91  101  102  106  107  108  125  128\n",
      "  139  140  144  145  147  152  157  162  187  190  194  198  203  204\n",
      "  208  220  232  233  238  241  244  250  251  254  255  260  261  262\n",
      "  267  268  270  278  279  287  293  294  301  303  309  310  312  315\n",
      "  318  328  335  339  340  342  344  345  354  357  359  360  379  384\n",
      "  390  391  393  426  431  438  440  441  442  455  459  468  474  475\n",
      "  477  486  487  490  505  506  511  512  513  518  522  532  535  551\n",
      "  557  568  574  583  585  588  593  602  609  610  633  636  642  646\n",
      "  653  665  667  676  689  703  708  715  717  718  721  724  731  733\n",
      "  750  757  763  766  772  774  781  784  792  795  810  812  813  815\n",
      "  818  819  822  828  838  855  876  878  884  892  893  897  904  906\n",
      "  912  915  916  926  930  933  937  943  946  963  966  970  978  980\n",
      "  985  986  987  993  997 1000 1010 1017 1025 1029 1030 1039 1041 1045\n",
      " 1049 1054 1055 1056 1058 1063 1067 1074 1076 1079 1081 1083 1086 1088\n",
      " 1091 1096 1097 1099 1103 1105 1106 1117 1126 1136 1138 1142 1145 1146\n",
      " 1147 1155 1158 1165 1168 1173 1175 1183 1187 1188 1190 1192 1193 1205\n",
      " 1210 1211 1213 1217 1222 1224 1226 1231 1238 1244 1252 1255 1257 1258\n",
      " 1260 1263 1264 1279 1293 1296 1301 1302 1315 1316 1322 1323 1335 1339\n",
      " 1345 1354 1372 1374 1403 1417 1419 1426 1444 1449 1452 1453 1454 1455\n",
      " 1463 1467 1476 1477 1482 1485 1486 1512 1528 1529 1537 1538 1539 1543\n",
      " 1549 1550 1554 1568 1570 1573 1588 1592 1599 1603 1604 1610 1611 1612\n",
      " 1620 1626 1627 1628 1636 1637 1639 1648 1656 1661 1663 1665 1673 1676\n",
      " 1677 1678 1679 1683 1686 1693 1694 1696 1700 1709 1714 1716 1717 1724\n",
      " 1725 1726 1735 1737 1748 1749 1753 1756 1758 1771 1773 1779 1780 1784\n",
      " 1785 1786 1789 1790 1798 1801 1806 1817 1819 1827 1828 1829 1840 1841\n",
      " 1845 1846 1854 1857 1859 1861 1866 1880 1884 1885 1894 1897 1901 1918\n",
      " 1922 1925 1929 1930 1934 1942 1959 1961 1964 1977 1980 1981 1989 1994\n",
      " 1999 2000 2001 2005 2010 2014 2016 2029 2037 2043 2053 2055 2060 2064\n",
      " 2066 2073 2076 2079 2082 2085 2090 2094 2108 2109 2110 2111 2114 2128\n",
      " 2130 2132 2133 2144 2147 2158 2168 2170 2175 2184 2190 2192 2196 2207\n",
      " 2209 2212 2233 2234 2235 2238 2239 2241 2242 2248 2262 2277 2281 2295\n",
      " 2302 2312 2313 2326 2332 2345 2355 2358 2363 2365 2366 2368 2369 2370\n",
      " 2373 2382 2396 2401 2411 2412 2416 2424 2432 2433 2438 2441 2448 2450\n",
      " 2457 2464 2480 2485 2488 2490 2491 2493 2494 2501 2505 2506 2510 2518\n",
      " 2519 2521 2522 2535 2552 2556 2558 2564 2565 2566 2570 2572 2573 2575\n",
      " 2577 2580 2605 2606 2611 2612 2616 2617 2618 2626 2632 2648 2650 2658\n",
      " 2661 2664 2667 2668 2672 2673 2674 2694 2696 2699 2706 2720 2728 2734\n",
      " 2740 2741 2761 2762 2764 2770 2771 2772 2774 2776 2784 2790 2791 2792\n",
      " 2797 2805 2807 2812 2828 2835 2836 2837 2838 2839 2840 2844 2847 2849\n",
      " 2857 2862 2865 2869 2871 2878 2879 2883 2885 2887 2888 2890 2909 2910\n",
      " 2916 2919 2921 2926 2932 2933 2936 2939 2941 2945 2953 2955 2961 2964\n",
      " 2971 2975 2978 2985 2988 2991 2992 3002 3004 3006 3007 3010 3012 3013\n",
      " 3015 3016 3019 3021 3030 3037 3042 3043 3044 3047 3048 3059 3061 3071\n",
      " 3073 3077 3079 3090 3093 3103 3124 3127 3129 3132 3140 3147 3156 3158\n",
      " 3161 3172 3181 3188 3189 3195 3196 3197 3198 3203 3210 3213 3215 3218\n",
      " 3225 3235 3245 3250 3254 3255 3257 3262 3268 3275 3278 3283 3288 3301\n",
      " 3303 3308 3334 3336 3358 3367 3369 3370 3374 3380 3394 3404 3406 3408\n",
      " 3415 3416 3417 3430 3436 3438 3454 3467 3471 3477 3485 3511 3522 3525\n",
      " 3532 3535 3542 3545 3568 3571 3573 3575 3577 3582 3584 3588 3590 3597\n",
      " 3600 3603 3606 3607 3613 3615 3618 3621 3629 3631 3634 3639 3641 3644\n",
      " 3652 3656 3659 3670 3671 3675 3677 3679 3684 3687 3690 3694 3696 3698\n",
      " 3699 3708 3710 3711 3712 3718 3731 3738 3747 3753 3754 3760 3769 3771\n",
      " 3777 3778 3780 3789 3790 3791 3792 3797 3798 3799 3800 3806 3808 3814\n",
      " 3815 3819 3826 3831 3838 3850 3852 3856 3866 3867 3868 3871 3872 3880\n",
      " 3883 3885 3897 3910 3911 3913 3914 3919 3921 3922 3927 3928 3929 3939\n",
      " 3940 3948 3952 3960 3965 3973 3974 3975 3977 3985 3998 3999 4001 4006\n",
      " 4012 4013 4017 4019 4030 4037 4042 4045 4048 4049 4051 4052 4055 4059\n",
      " 4061 4069 4075 4076 4080 4084 4086 4089 4094 4096 4104 4109 4116 4118\n",
      " 4146 4148 4149 4156 4157 4162 4168 4169 4171]\n",
      "TRAIN: [   0    1    2 ... 4171 4172 4176] TEST: [  16   32   35   51   56   60   62   65   73   75   78   79   81   83\n",
      "   89   95   96  103  105  110  111  114  120  123  127  129  131  143\n",
      "  150  155  165  171  172  178  181  183  184  186  193  205  210  212\n",
      "  213  222  225  230  231  236  239  243  247  258  265  266  273  284\n",
      "  313  319  324  331  336  341  355  356  358  362  363  364  367  370\n",
      "  371  372  373  374  377  382  389  395  397  401  403  412  416  417\n",
      "  420  421  432  434  435  439  445  448  450  464  466  471  479  484\n",
      "  492  494  495  498  510  523  524  539  540  542  549  552  554  561\n",
      "  571  580  592  608  611  613  614  625  626  630  631  632  644  645\n",
      "  649  656  658  660  662  669  679  681  693  695  697  707  726  729\n",
      "  737  740  742  759  760  761  765  769  771  782  785  787  790  798\n",
      "  801  808  811  814  823  824  833  839  844  853  858  863  870  875\n",
      "  877  881  887  889  901  907  911  919  920  947  948  957  959  960\n",
      "  968  974  992  994 1008 1016 1019 1024 1026 1031 1034 1035 1050 1057\n",
      " 1060 1064 1075 1080 1089 1102 1121 1123 1124 1125 1132 1135 1143 1154\n",
      " 1156 1164 1166 1169 1178 1186 1189 1200 1214 1216 1218 1227 1228 1229\n",
      " 1233 1234 1265 1274 1286 1291 1294 1295 1307 1312 1320 1321 1325 1340\n",
      " 1342 1344 1356 1360 1361 1365 1375 1378 1383 1391 1394 1401 1405 1406\n",
      " 1407 1408 1415 1421 1433 1437 1439 1440 1442 1456 1459 1466 1481 1484\n",
      " 1492 1498 1500 1502 1506 1508 1510 1516 1518 1520 1524 1527 1534 1545\n",
      " 1557 1575 1576 1585 1591 1594 1595 1597 1598 1607 1609 1613 1614 1616\n",
      " 1622 1624 1629 1630 1631 1635 1650 1655 1659 1664 1668 1674 1681 1682\n",
      " 1685 1688 1689 1704 1706 1711 1719 1727 1729 1730 1741 1743 1745 1755\n",
      " 1776 1781 1782 1787 1788 1796 1797 1802 1803 1807 1809 1810 1814 1816\n",
      " 1820 1821 1833 1842 1843 1848 1851 1858 1860 1864 1870 1873 1874 1876\n",
      " 1882 1890 1891 1893 1903 1909 1919 1921 1926 1932 1935 1937 1946 1960\n",
      " 1968 1984 1985 1988 1995 1996 1998 2007 2015 2018 2020 2026 2028 2032\n",
      " 2035 2045 2050 2056 2061 2068 2069 2077 2083 2086 2092 2093 2097 2098\n",
      " 2099 2113 2116 2119 2122 2127 2129 2136 2138 2145 2149 2153 2156 2167\n",
      " 2179 2191 2199 2202 2206 2208 2218 2220 2225 2228 2229 2236 2245 2246\n",
      " 2253 2256 2259 2264 2266 2267 2276 2279 2283 2286 2289 2290 2291 2303\n",
      " 2305 2309 2311 2314 2316 2317 2320 2321 2325 2328 2333 2336 2349 2356\n",
      " 2360 2364 2376 2380 2386 2393 2394 2395 2397 2398 2400 2402 2413 2414\n",
      " 2419 2421 2422 2426 2428 2437 2442 2449 2451 2454 2456 2458 2461 2474\n",
      " 2479 2489 2495 2499 2504 2508 2512 2514 2515 2517 2520 2524 2529 2532\n",
      " 2539 2541 2544 2548 2551 2555 2557 2561 2568 2571 2576 2579 2581 2585\n",
      " 2589 2590 2593 2594 2596 2598 2608 2613 2614 2623 2624 2634 2636 2637\n",
      " 2639 2641 2643 2647 2649 2652 2654 2662 2670 2686 2690 2695 2710 2716\n",
      " 2725 2726 2731 2733 2737 2739 2746 2747 2752 2754 2785 2789 2799 2800\n",
      " 2802 2808 2809 2816 2819 2822 2831 2832 2841 2845 2870 2874 2877 2892\n",
      " 2894 2902 2907 2912 2913 2915 2918 2920 2922 2925 2927 2929 2935 2940\n",
      " 2942 2952 2958 2959 2960 2963 2966 2969 2973 2979 2982 2983 2986 2993\n",
      " 2998 3000 3008 3011 3017 3018 3023 3027 3028 3029 3033 3035 3041 3050\n",
      " 3054 3058 3072 3074 3078 3095 3096 3097 3098 3102 3104 3105 3109 3110\n",
      " 3112 3122 3131 3133 3134 3137 3139 3153 3164 3174 3177 3179 3180 3183\n",
      " 3190 3214 3216 3223 3226 3227 3230 3233 3238 3240 3251 3253 3256 3258\n",
      " 3259 3261 3263 3270 3274 3276 3284 3302 3306 3309 3320 3322 3323 3324\n",
      " 3325 3329 3333 3338 3342 3343 3344 3345 3350 3354 3355 3360 3376 3381\n",
      " 3385 3390 3392 3393 3397 3400 3407 3412 3414 3423 3435 3437 3440 3443\n",
      " 3444 3447 3448 3452 3456 3457 3458 3459 3460 3462 3470 3474 3476 3482\n",
      " 3484 3490 3500 3504 3506 3512 3523 3534 3538 3554 3557 3570 3572 3580\n",
      " 3583 3586 3589 3592 3596 3598 3602 3604 3609 3619 3625 3626 3636 3637\n",
      " 3648 3649 3650 3663 3664 3665 3666 3668 3669 3673 3676 3683 3685 3692\n",
      " 3697 3700 3701 3705 3713 3717 3719 3721 3724 3736 3746 3748 3749 3755\n",
      " 3761 3768 3775 3776 3782 3788 3794 3801 3802 3804 3817 3818 3820 3821\n",
      " 3832 3837 3848 3849 3853 3861 3864 3874 3876 3878 3888 3890 3898 3907\n",
      " 3923 3931 3933 3937 3941 3950 3951 3953 3963 3969 3976 3982 3984 3986\n",
      " 3994 3995 3996 4005 4007 4015 4024 4028 4033 4034 4044 4047 4073 4077\n",
      " 4078 4079 4097 4098 4101 4103 4111 4112 4115 4121 4127 4132 4134 4138\n",
      " 4139 4145 4147 4151 4155 4166 4173 4174 4175]\n",
      "TRAIN: [   1    2    4 ... 4174 4175 4176] TEST: [   0    3    7   12   21   24   25   26   28   46   63   67   74   86\n",
      "   90   93   94   99  100  112  115  116  126  130  136  146  151  153\n",
      "  160  163  164  166  167  168  174  176  180  197  199  201  207  209\n",
      "  216  221  237  246  256  274  275  280  281  282  288  291  292  297\n",
      "  307  321  323  325  327  329  334  337  343  348  350  365  375  387\n",
      "  400  404  407  409  419  423  424  428  429  430  433  437  447  449\n",
      "  451  460  462  469  470  497  504  508  509  515  525  537  544  550\n",
      "  556  560  573  577  584  586  591  594  595  603  604  605  606  607\n",
      "  612  617  622  623  624  627  637  640  647  650  659  664  671  673\n",
      "  680  691  694  696  698  699  705  709  714  730  732  734  736  738\n",
      "  739  741  747  749  753  754  755  756  767  770  777  780  786  797\n",
      "  800  802  804  807  809  816  821  827  830  834  837  843  845  848\n",
      "  851  854  857  859  860  865  869  872  873  885  894  902  903  908\n",
      "  922  925  928  929  931  932  941  945  950  952  956  967  973  975\n",
      "  990 1004 1006 1007 1011 1020 1022 1028 1033 1040 1046 1048 1053 1066\n",
      " 1071 1072 1085 1090 1092 1104 1107 1111 1112 1113 1130 1131 1133 1134\n",
      " 1141 1144 1149 1152 1153 1159 1162 1163 1167 1172 1176 1177 1179 1181\n",
      " 1194 1198 1201 1202 1204 1206 1207 1208 1209 1215 1219 1221 1241 1243\n",
      " 1247 1249 1250 1251 1253 1272 1278 1289 1297 1298 1304 1305 1306 1308\n",
      " 1309 1314 1331 1333 1337 1346 1348 1350 1352 1353 1369 1381 1384 1389\n",
      " 1392 1395 1398 1400 1402 1404 1409 1413 1416 1425 1429 1434 1435 1438\n",
      " 1441 1443 1445 1447 1461 1468 1469 1470 1472 1479 1480 1483 1488 1497\n",
      " 1514 1517 1522 1531 1532 1541 1542 1546 1551 1552 1556 1558 1561 1562\n",
      " 1563 1565 1566 1574 1578 1579 1582 1584 1589 1596 1600 1605 1608 1617\n",
      " 1619 1623 1634 1638 1640 1641 1645 1653 1660 1667 1671 1672 1684 1690\n",
      " 1701 1705 1707 1718 1720 1722 1723 1731 1734 1740 1744 1747 1750 1769\n",
      " 1777 1792 1795 1799 1800 1805 1812 1822 1823 1834 1838 1844 1847 1849\n",
      " 1862 1863 1868 1871 1879 1883 1889 1896 1899 1904 1908 1910 1911 1913\n",
      " 1915 1924 1933 1938 1941 1954 1956 1963 1966 1967 1970 1971 1973 1975\n",
      " 1978 1986 1987 1993 2002 2003 2006 2008 2009 2011 2021 2022 2023 2040\n",
      " 2042 2046 2051 2059 2071 2080 2081 2084 2089 2091 2105 2107 2117 2120\n",
      " 2121 2135 2139 2141 2146 2150 2152 2154 2157 2159 2163 2169 2171 2173\n",
      " 2176 2177 2182 2185 2186 2187 2195 2197 2214 2217 2221 2222 2227 2237\n",
      " 2247 2251 2257 2260 2261 2269 2273 2274 2280 2282 2292 2296 2298 2304\n",
      " 2322 2334 2335 2338 2339 2341 2344 2352 2353 2354 2371 2375 2384 2387\n",
      " 2388 2389 2391 2392 2403 2405 2417 2418 2425 2431 2435 2440 2444 2446\n",
      " 2463 2467 2469 2471 2477 2492 2496 2498 2502 2503 2511 2516 2528 2536\n",
      " 2538 2546 2547 2550 2562 2582 2595 2599 2603 2607 2609 2610 2633 2642\n",
      " 2646 2659 2660 2665 2671 2676 2679 2681 2683 2684 2685 2687 2691 2693\n",
      " 2701 2711 2712 2721 2723 2732 2738 2742 2744 2745 2748 2749 2750 2753\n",
      " 2757 2758 2763 2766 2767 2775 2778 2782 2783 2786 2787 2798 2811 2813\n",
      " 2814 2818 2820 2825 2826 2827 2830 2834 2850 2851 2852 2854 2860 2863\n",
      " 2867 2880 2881 2882 2884 2893 2897 2899 2900 2903 2904 2908 2924 2930\n",
      " 2934 2937 2938 2956 2957 2965 2967 2974 2977 2987 2989 2995 2997 2999\n",
      " 3024 3026 3046 3052 3056 3057 3060 3064 3067 3083 3085 3089 3091 3107\n",
      " 3108 3113 3114 3115 3116 3123 3125 3128 3130 3143 3146 3148 3150 3152\n",
      " 3165 3166 3168 3186 3187 3191 3192 3200 3204 3205 3207 3208 3219 3220\n",
      " 3221 3224 3243 3246 3252 3264 3273 3277 3279 3280 3281 3282 3289 3290\n",
      " 3291 3292 3298 3299 3300 3310 3315 3317 3318 3330 3331 3332 3337 3341\n",
      " 3348 3356 3361 3362 3372 3386 3395 3396 3398 3413 3418 3419 3421 3425\n",
      " 3426 3432 3441 3445 3450 3451 3453 3455 3463 3465 3466 3468 3483 3486\n",
      " 3491 3498 3505 3510 3513 3516 3520 3531 3533 3547 3548 3550 3560 3561\n",
      " 3566 3579 3581 3587 3591 3608 3611 3612 3616 3622 3623 3624 3630 3635\n",
      " 3638 3642 3646 3647 3651 3661 3674 3678 3680 3695 3707 3709 3726 3729\n",
      " 3734 3740 3742 3744 3762 3763 3779 3781 3786 3796 3807 3816 3822 3834\n",
      " 3835 3840 3843 3846 3847 3854 3869 3879 3882 3884 3886 3891 3893 3894\n",
      " 3900 3901 3904 3906 3912 3918 3925 3926 3930 3936 3938 3942 3944 3947\n",
      " 3957 3959 3961 3964 4002 4003 4004 4009 4010 4023 4026 4038 4050 4056\n",
      " 4058 4060 4065 4067 4071 4081 4082 4099 4105 4106 4107 4108 4114 4123\n",
      " 4128 4136 4140 4143 4150 4152 4158 4159 4165]\n"
     ]
    }
   ],
   "source": [
    "for train_index , test_index in kfold.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train ,x_test  = X.iloc[train_index] ,X.iloc[test_index]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    2    3 ... 4173 4174 4175] TEST: [   1    4   10   14   17   22   23   30   31   33   34   39   42   45\n",
      "   49   57   61   70   72   85   87   88   92  104  117  118  124  134\n",
      "  138  142  148  154  156  170  173  182  185  189  192  195  196  202\n",
      "  214  217  223  224  226  227  229  242  245  248  253  257  276  285\n",
      "  286  289  290  295  296  298  302  304  306  308  311  322  326  333\n",
      "  346  347  352  378  381  398  402  405  408  410  415  418  436  443\n",
      "  444  452  453  457  463  465  467  473  480  481  482  483  485  489\n",
      "  491  496  499  500  501  502  514  517  520  521  526  527  528  530\n",
      "  531  533  534  536  538  541  543  545  546  548  555  558  562  566\n",
      "  567  569  570  572  575  576  578  581  582  587  598  599  615  621\n",
      "  629  634  635  638  639  641  643  651  661  663  666  668  675  678\n",
      "  682  683  684  685  690  692  704  706  712  716  727  735  748  751\n",
      "  768  773  775  776  799  803  817  825  829  836  840  841  842  861\n",
      "  866  867  868  882  888  891  895  898  900  905  910  914  917  927\n",
      "  935  938  944  949  958  961  962  971  977  979  982  983  991  996\n",
      "  998 1001 1002 1005 1009 1012 1018 1021 1042 1043 1059 1062 1065 1068\n",
      " 1069 1073 1077 1082 1084 1087 1093 1095 1098 1109 1114 1115 1116 1118\n",
      " 1119 1120 1129 1161 1170 1180 1191 1195 1230 1235 1236 1239 1245 1248\n",
      " 1259 1262 1267 1270 1273 1275 1276 1277 1282 1285 1288 1292 1303 1313\n",
      " 1319 1326 1328 1329 1330 1332 1334 1336 1341 1343 1347 1349 1362 1363\n",
      " 1364 1366 1379 1380 1385 1399 1410 1412 1423 1430 1431 1432 1436 1446\n",
      " 1450 1457 1460 1465 1471 1474 1475 1489 1490 1491 1493 1495 1496 1499\n",
      " 1501 1505 1507 1509 1511 1523 1526 1533 1536 1553 1559 1567 1571 1572\n",
      " 1577 1580 1581 1583 1586 1601 1602 1618 1621 1633 1643 1651 1652 1654\n",
      " 1658 1662 1670 1675 1680 1687 1691 1692 1699 1703 1710 1721 1738 1746\n",
      " 1751 1754 1762 1767 1768 1770 1772 1774 1775 1783 1804 1808 1813 1818\n",
      " 1825 1830 1831 1835 1836 1837 1850 1852 1853 1869 1875 1881 1886 1887\n",
      " 1888 1892 1895 1900 1905 1906 1907 1920 1927 1928 1931 1936 1943 1947\n",
      " 1950 1953 1957 1965 1976 1979 1982 1990 1991 1992 2004 2012 2017 2031\n",
      " 2036 2044 2052 2054 2058 2062 2065 2067 2072 2078 2101 2102 2115 2137\n",
      " 2140 2148 2161 2164 2166 2172 2178 2180 2181 2188 2189 2193 2194 2198\n",
      " 2203 2204 2205 2211 2215 2219 2224 2226 2231 2232 2243 2244 2249 2250\n",
      " 2252 2258 2268 2275 2278 2284 2288 2294 2297 2299 2307 2310 2324 2330\n",
      " 2337 2343 2346 2348 2361 2362 2367 2377 2381 2404 2406 2409 2410 2427\n",
      " 2429 2430 2434 2439 2445 2447 2459 2460 2465 2470 2475 2482 2483 2484\n",
      " 2486 2497 2507 2527 2531 2533 2537 2545 2553 2559 2567 2574 2578 2583\n",
      " 2584 2586 2587 2592 2601 2615 2619 2621 2625 2627 2628 2635 2640 2644\n",
      " 2645 2651 2653 2655 2656 2663 2666 2678 2680 2702 2703 2704 2705 2709\n",
      " 2713 2715 2718 2719 2727 2729 2736 2743 2751 2756 2769 2781 2788 2793\n",
      " 2794 2796 2803 2804 2806 2815 2817 2821 2829 2846 2848 2855 2856 2859\n",
      " 2868 2873 2875 2876 2891 2898 2901 2905 2906 2914 2923 2928 2943 2946\n",
      " 2949 2950 2954 2962 2968 2972 2976 2980 2984 3001 3005 3009 3022 3025\n",
      " 3031 3032 3036 3038 3040 3049 3051 3055 3062 3063 3065 3066 3068 3075\n",
      " 3081 3086 3088 3092 3100 3106 3111 3117 3118 3120 3121 3126 3142 3145\n",
      " 3151 3155 3157 3160 3163 3176 3178 3185 3193 3194 3199 3211 3217 3222\n",
      " 3228 3229 3231 3236 3237 3239 3241 3242 3244 3247 3248 3265 3271 3272\n",
      " 3286 3287 3295 3297 3304 3305 3314 3316 3319 3326 3328 3346 3347 3351\n",
      " 3357 3359 3364 3366 3368 3371 3373 3378 3379 3388 3399 3402 3410 3420\n",
      " 3422 3428 3429 3434 3442 3449 3464 3469 3472 3475 3479 3487 3488 3492\n",
      " 3493 3494 3496 3497 3499 3501 3502 3507 3508 3514 3519 3524 3526 3528\n",
      " 3530 3539 3540 3541 3543 3544 3546 3551 3552 3553 3555 3556 3558 3564\n",
      " 3567 3578 3594 3595 3605 3610 3614 3617 3620 3628 3632 3640 3653 3654\n",
      " 3657 3686 3693 3703 3706 3716 3720 3722 3727 3730 3733 3735 3741 3752\n",
      " 3759 3764 3766 3772 3774 3784 3787 3795 3803 3812 3823 3825 3827 3830\n",
      " 3836 3841 3842 3844 3851 3857 3858 3859 3865 3870 3873 3877 3881 3896\n",
      " 3899 3902 3908 3909 3917 3924 3943 3949 3954 3956 3958 3966 3968 3971\n",
      " 3972 3979 3980 3981 3983 3987 3988 3990 3992 3993 3997 4000 4011 4014\n",
      " 4016 4020 4021 4022 4032 4035 4036 4039 4040 4041 4043 4062 4064 4066\n",
      " 4070 4072 4083 4092 4093 4102 4119 4120 4122 4124 4125 4126 4131 4133\n",
      " 4135 4144 4153 4154 4160 4161 4164 4167 4172 4176]\n",
      "TRAIN: [   0    1    3 ... 4174 4175 4176] TEST: [   2    5    9   11   15   27   29   36   37   40   44   50   53   64\n",
      "   66   69   71   76   82   97   98  109  113  119  121  122  132  133\n",
      "  135  137  141  149  158  159  161  169  175  177  179  188  191  200\n",
      "  206  211  215  218  219  228  234  235  240  249  252  259  263  264\n",
      "  269  271  272  277  283  299  300  305  314  316  317  320  330  332\n",
      "  338  349  351  353  361  366  368  369  376  380  383  385  386  388\n",
      "  392  394  396  399  406  411  413  414  422  425  427  446  454  456\n",
      "  458  461  472  476  478  488  493  503  507  516  519  529  547  553\n",
      "  559  563  564  565  579  589  590  596  597  600  601  616  618  619\n",
      "  620  628  648  652  654  655  657  670  672  674  677  686  687  688\n",
      "  700  701  702  710  711  713  719  720  722  723  725  728  743  744\n",
      "  745  746  752  758  762  764  778  779  783  788  789  791  793  794\n",
      "  796  805  806  820  826  831  832  835  846  847  849  850  852  856\n",
      "  862  864  871  874  879  880  883  886  890  896  899  909  913  918\n",
      "  921  923  924  934  936  939  940  942  951  953  954  955  964  965\n",
      "  969  972  976  981  984  988  989  995  999 1003 1013 1014 1015 1023\n",
      " 1027 1032 1036 1037 1038 1044 1047 1051 1052 1061 1070 1078 1094 1100\n",
      " 1101 1108 1110 1122 1127 1128 1137 1139 1140 1148 1150 1151 1157 1160\n",
      " 1171 1174 1182 1184 1185 1196 1197 1199 1203 1212 1220 1223 1225 1232\n",
      " 1237 1240 1242 1246 1254 1256 1261 1266 1268 1269 1271 1280 1281 1283\n",
      " 1284 1287 1290 1299 1300 1310 1311 1317 1318 1324 1327 1338 1351 1355\n",
      " 1357 1358 1359 1367 1368 1370 1371 1373 1376 1377 1382 1386 1387 1388\n",
      " 1390 1393 1396 1397 1411 1414 1418 1420 1422 1424 1427 1428 1448 1451\n",
      " 1458 1462 1464 1473 1478 1487 1494 1503 1504 1513 1515 1519 1521 1525\n",
      " 1530 1535 1540 1544 1547 1548 1555 1560 1564 1569 1587 1590 1593 1606\n",
      " 1615 1625 1632 1642 1644 1646 1647 1649 1657 1666 1669 1695 1697 1698\n",
      " 1702 1708 1712 1713 1715 1728 1732 1733 1736 1739 1742 1752 1757 1759\n",
      " 1760 1761 1763 1764 1765 1766 1778 1791 1793 1794 1811 1815 1824 1826\n",
      " 1832 1839 1855 1856 1865 1867 1872 1877 1878 1898 1902 1912 1914 1916\n",
      " 1917 1923 1939 1940 1944 1945 1948 1949 1951 1952 1955 1958 1962 1969\n",
      " 1972 1974 1983 1997 2013 2019 2024 2025 2027 2030 2033 2034 2038 2039\n",
      " 2041 2047 2048 2049 2057 2063 2070 2074 2075 2087 2088 2095 2096 2100\n",
      " 2103 2104 2106 2112 2118 2123 2124 2125 2126 2131 2134 2142 2143 2151\n",
      " 2155 2160 2162 2165 2174 2183 2200 2201 2210 2213 2216 2223 2230 2240\n",
      " 2254 2255 2263 2265 2270 2271 2272 2285 2287 2293 2300 2301 2306 2308\n",
      " 2315 2318 2319 2323 2327 2329 2331 2340 2342 2347 2350 2351 2357 2359\n",
      " 2372 2374 2378 2379 2383 2385 2390 2399 2407 2408 2415 2420 2423 2436\n",
      " 2443 2452 2453 2455 2462 2466 2468 2472 2473 2476 2478 2481 2487 2500\n",
      " 2509 2513 2523 2525 2526 2530 2534 2540 2542 2543 2549 2554 2560 2563\n",
      " 2569 2588 2591 2597 2600 2602 2604 2620 2622 2629 2630 2631 2638 2657\n",
      " 2669 2675 2677 2682 2688 2689 2692 2697 2698 2700 2707 2708 2714 2717\n",
      " 2722 2724 2730 2735 2755 2759 2760 2765 2768 2773 2777 2779 2780 2795\n",
      " 2801 2810 2823 2824 2833 2842 2843 2853 2858 2861 2864 2866 2872 2886\n",
      " 2889 2895 2896 2911 2917 2931 2944 2947 2948 2951 2970 2981 2990 2994\n",
      " 2996 3003 3014 3020 3034 3039 3045 3053 3069 3070 3076 3080 3082 3084\n",
      " 3087 3094 3099 3101 3119 3135 3136 3138 3141 3144 3149 3154 3159 3162\n",
      " 3167 3169 3170 3171 3173 3175 3182 3184 3201 3202 3206 3209 3212 3232\n",
      " 3234 3249 3260 3266 3267 3269 3285 3293 3294 3296 3307 3311 3312 3313\n",
      " 3321 3327 3335 3339 3340 3349 3352 3353 3363 3365 3375 3377 3382 3383\n",
      " 3384 3387 3389 3391 3401 3403 3405 3409 3411 3424 3427 3431 3433 3439\n",
      " 3446 3461 3473 3478 3480 3481 3489 3495 3503 3509 3515 3517 3518 3521\n",
      " 3527 3529 3536 3537 3549 3559 3562 3563 3565 3569 3574 3576 3585 3593\n",
      " 3599 3601 3627 3633 3643 3645 3655 3658 3660 3662 3667 3672 3681 3682\n",
      " 3688 3689 3691 3702 3704 3714 3715 3723 3725 3728 3732 3737 3739 3743\n",
      " 3745 3750 3751 3756 3757 3758 3765 3767 3770 3773 3783 3785 3793 3805\n",
      " 3809 3810 3811 3813 3824 3828 3829 3833 3839 3845 3855 3860 3862 3863\n",
      " 3875 3887 3889 3892 3895 3903 3905 3915 3916 3920 3932 3934 3935 3945\n",
      " 3946 3955 3962 3967 3970 3978 3989 3991 4008 4018 4025 4027 4029 4031\n",
      " 4046 4053 4054 4057 4063 4068 4074 4085 4087 4088 4090 4091 4095 4100\n",
      " 4110 4113 4117 4129 4130 4137 4141 4142 4163 4170]\n",
      "TRAIN: [   0    1    2 ... 4174 4175 4176] TEST: [   6    8   13   18   19   20   38   41   43   47   48   52   54   55\n",
      "   58   59   68   77   80   84   91  101  102  106  107  108  125  128\n",
      "  139  140  144  145  147  152  157  162  187  190  194  198  203  204\n",
      "  208  220  232  233  238  241  244  250  251  254  255  260  261  262\n",
      "  267  268  270  278  279  287  293  294  301  303  309  310  312  315\n",
      "  318  328  335  339  340  342  344  345  354  357  359  360  379  384\n",
      "  390  391  393  426  431  438  440  441  442  455  459  468  474  475\n",
      "  477  486  487  490  505  506  511  512  513  518  522  532  535  551\n",
      "  557  568  574  583  585  588  593  602  609  610  633  636  642  646\n",
      "  653  665  667  676  689  703  708  715  717  718  721  724  731  733\n",
      "  750  757  763  766  772  774  781  784  792  795  810  812  813  815\n",
      "  818  819  822  828  838  855  876  878  884  892  893  897  904  906\n",
      "  912  915  916  926  930  933  937  943  946  963  966  970  978  980\n",
      "  985  986  987  993  997 1000 1010 1017 1025 1029 1030 1039 1041 1045\n",
      " 1049 1054 1055 1056 1058 1063 1067 1074 1076 1079 1081 1083 1086 1088\n",
      " 1091 1096 1097 1099 1103 1105 1106 1117 1126 1136 1138 1142 1145 1146\n",
      " 1147 1155 1158 1165 1168 1173 1175 1183 1187 1188 1190 1192 1193 1205\n",
      " 1210 1211 1213 1217 1222 1224 1226 1231 1238 1244 1252 1255 1257 1258\n",
      " 1260 1263 1264 1279 1293 1296 1301 1302 1315 1316 1322 1323 1335 1339\n",
      " 1345 1354 1372 1374 1403 1417 1419 1426 1444 1449 1452 1453 1454 1455\n",
      " 1463 1467 1476 1477 1482 1485 1486 1512 1528 1529 1537 1538 1539 1543\n",
      " 1549 1550 1554 1568 1570 1573 1588 1592 1599 1603 1604 1610 1611 1612\n",
      " 1620 1626 1627 1628 1636 1637 1639 1648 1656 1661 1663 1665 1673 1676\n",
      " 1677 1678 1679 1683 1686 1693 1694 1696 1700 1709 1714 1716 1717 1724\n",
      " 1725 1726 1735 1737 1748 1749 1753 1756 1758 1771 1773 1779 1780 1784\n",
      " 1785 1786 1789 1790 1798 1801 1806 1817 1819 1827 1828 1829 1840 1841\n",
      " 1845 1846 1854 1857 1859 1861 1866 1880 1884 1885 1894 1897 1901 1918\n",
      " 1922 1925 1929 1930 1934 1942 1959 1961 1964 1977 1980 1981 1989 1994\n",
      " 1999 2000 2001 2005 2010 2014 2016 2029 2037 2043 2053 2055 2060 2064\n",
      " 2066 2073 2076 2079 2082 2085 2090 2094 2108 2109 2110 2111 2114 2128\n",
      " 2130 2132 2133 2144 2147 2158 2168 2170 2175 2184 2190 2192 2196 2207\n",
      " 2209 2212 2233 2234 2235 2238 2239 2241 2242 2248 2262 2277 2281 2295\n",
      " 2302 2312 2313 2326 2332 2345 2355 2358 2363 2365 2366 2368 2369 2370\n",
      " 2373 2382 2396 2401 2411 2412 2416 2424 2432 2433 2438 2441 2448 2450\n",
      " 2457 2464 2480 2485 2488 2490 2491 2493 2494 2501 2505 2506 2510 2518\n",
      " 2519 2521 2522 2535 2552 2556 2558 2564 2565 2566 2570 2572 2573 2575\n",
      " 2577 2580 2605 2606 2611 2612 2616 2617 2618 2626 2632 2648 2650 2658\n",
      " 2661 2664 2667 2668 2672 2673 2674 2694 2696 2699 2706 2720 2728 2734\n",
      " 2740 2741 2761 2762 2764 2770 2771 2772 2774 2776 2784 2790 2791 2792\n",
      " 2797 2805 2807 2812 2828 2835 2836 2837 2838 2839 2840 2844 2847 2849\n",
      " 2857 2862 2865 2869 2871 2878 2879 2883 2885 2887 2888 2890 2909 2910\n",
      " 2916 2919 2921 2926 2932 2933 2936 2939 2941 2945 2953 2955 2961 2964\n",
      " 2971 2975 2978 2985 2988 2991 2992 3002 3004 3006 3007 3010 3012 3013\n",
      " 3015 3016 3019 3021 3030 3037 3042 3043 3044 3047 3048 3059 3061 3071\n",
      " 3073 3077 3079 3090 3093 3103 3124 3127 3129 3132 3140 3147 3156 3158\n",
      " 3161 3172 3181 3188 3189 3195 3196 3197 3198 3203 3210 3213 3215 3218\n",
      " 3225 3235 3245 3250 3254 3255 3257 3262 3268 3275 3278 3283 3288 3301\n",
      " 3303 3308 3334 3336 3358 3367 3369 3370 3374 3380 3394 3404 3406 3408\n",
      " 3415 3416 3417 3430 3436 3438 3454 3467 3471 3477 3485 3511 3522 3525\n",
      " 3532 3535 3542 3545 3568 3571 3573 3575 3577 3582 3584 3588 3590 3597\n",
      " 3600 3603 3606 3607 3613 3615 3618 3621 3629 3631 3634 3639 3641 3644\n",
      " 3652 3656 3659 3670 3671 3675 3677 3679 3684 3687 3690 3694 3696 3698\n",
      " 3699 3708 3710 3711 3712 3718 3731 3738 3747 3753 3754 3760 3769 3771\n",
      " 3777 3778 3780 3789 3790 3791 3792 3797 3798 3799 3800 3806 3808 3814\n",
      " 3815 3819 3826 3831 3838 3850 3852 3856 3866 3867 3868 3871 3872 3880\n",
      " 3883 3885 3897 3910 3911 3913 3914 3919 3921 3922 3927 3928 3929 3939\n",
      " 3940 3948 3952 3960 3965 3973 3974 3975 3977 3985 3998 3999 4001 4006\n",
      " 4012 4013 4017 4019 4030 4037 4042 4045 4048 4049 4051 4052 4055 4059\n",
      " 4061 4069 4075 4076 4080 4084 4086 4089 4094 4096 4104 4109 4116 4118\n",
      " 4146 4148 4149 4156 4157 4162 4168 4169 4171]\n",
      "TRAIN: [   0    1    2 ... 4171 4172 4176] TEST: [  16   32   35   51   56   60   62   65   73   75   78   79   81   83\n",
      "   89   95   96  103  105  110  111  114  120  123  127  129  131  143\n",
      "  150  155  165  171  172  178  181  183  184  186  193  205  210  212\n",
      "  213  222  225  230  231  236  239  243  247  258  265  266  273  284\n",
      "  313  319  324  331  336  341  355  356  358  362  363  364  367  370\n",
      "  371  372  373  374  377  382  389  395  397  401  403  412  416  417\n",
      "  420  421  432  434  435  439  445  448  450  464  466  471  479  484\n",
      "  492  494  495  498  510  523  524  539  540  542  549  552  554  561\n",
      "  571  580  592  608  611  613  614  625  626  630  631  632  644  645\n",
      "  649  656  658  660  662  669  679  681  693  695  697  707  726  729\n",
      "  737  740  742  759  760  761  765  769  771  782  785  787  790  798\n",
      "  801  808  811  814  823  824  833  839  844  853  858  863  870  875\n",
      "  877  881  887  889  901  907  911  919  920  947  948  957  959  960\n",
      "  968  974  992  994 1008 1016 1019 1024 1026 1031 1034 1035 1050 1057\n",
      " 1060 1064 1075 1080 1089 1102 1121 1123 1124 1125 1132 1135 1143 1154\n",
      " 1156 1164 1166 1169 1178 1186 1189 1200 1214 1216 1218 1227 1228 1229\n",
      " 1233 1234 1265 1274 1286 1291 1294 1295 1307 1312 1320 1321 1325 1340\n",
      " 1342 1344 1356 1360 1361 1365 1375 1378 1383 1391 1394 1401 1405 1406\n",
      " 1407 1408 1415 1421 1433 1437 1439 1440 1442 1456 1459 1466 1481 1484\n",
      " 1492 1498 1500 1502 1506 1508 1510 1516 1518 1520 1524 1527 1534 1545\n",
      " 1557 1575 1576 1585 1591 1594 1595 1597 1598 1607 1609 1613 1614 1616\n",
      " 1622 1624 1629 1630 1631 1635 1650 1655 1659 1664 1668 1674 1681 1682\n",
      " 1685 1688 1689 1704 1706 1711 1719 1727 1729 1730 1741 1743 1745 1755\n",
      " 1776 1781 1782 1787 1788 1796 1797 1802 1803 1807 1809 1810 1814 1816\n",
      " 1820 1821 1833 1842 1843 1848 1851 1858 1860 1864 1870 1873 1874 1876\n",
      " 1882 1890 1891 1893 1903 1909 1919 1921 1926 1932 1935 1937 1946 1960\n",
      " 1968 1984 1985 1988 1995 1996 1998 2007 2015 2018 2020 2026 2028 2032\n",
      " 2035 2045 2050 2056 2061 2068 2069 2077 2083 2086 2092 2093 2097 2098\n",
      " 2099 2113 2116 2119 2122 2127 2129 2136 2138 2145 2149 2153 2156 2167\n",
      " 2179 2191 2199 2202 2206 2208 2218 2220 2225 2228 2229 2236 2245 2246\n",
      " 2253 2256 2259 2264 2266 2267 2276 2279 2283 2286 2289 2290 2291 2303\n",
      " 2305 2309 2311 2314 2316 2317 2320 2321 2325 2328 2333 2336 2349 2356\n",
      " 2360 2364 2376 2380 2386 2393 2394 2395 2397 2398 2400 2402 2413 2414\n",
      " 2419 2421 2422 2426 2428 2437 2442 2449 2451 2454 2456 2458 2461 2474\n",
      " 2479 2489 2495 2499 2504 2508 2512 2514 2515 2517 2520 2524 2529 2532\n",
      " 2539 2541 2544 2548 2551 2555 2557 2561 2568 2571 2576 2579 2581 2585\n",
      " 2589 2590 2593 2594 2596 2598 2608 2613 2614 2623 2624 2634 2636 2637\n",
      " 2639 2641 2643 2647 2649 2652 2654 2662 2670 2686 2690 2695 2710 2716\n",
      " 2725 2726 2731 2733 2737 2739 2746 2747 2752 2754 2785 2789 2799 2800\n",
      " 2802 2808 2809 2816 2819 2822 2831 2832 2841 2845 2870 2874 2877 2892\n",
      " 2894 2902 2907 2912 2913 2915 2918 2920 2922 2925 2927 2929 2935 2940\n",
      " 2942 2952 2958 2959 2960 2963 2966 2969 2973 2979 2982 2983 2986 2993\n",
      " 2998 3000 3008 3011 3017 3018 3023 3027 3028 3029 3033 3035 3041 3050\n",
      " 3054 3058 3072 3074 3078 3095 3096 3097 3098 3102 3104 3105 3109 3110\n",
      " 3112 3122 3131 3133 3134 3137 3139 3153 3164 3174 3177 3179 3180 3183\n",
      " 3190 3214 3216 3223 3226 3227 3230 3233 3238 3240 3251 3253 3256 3258\n",
      " 3259 3261 3263 3270 3274 3276 3284 3302 3306 3309 3320 3322 3323 3324\n",
      " 3325 3329 3333 3338 3342 3343 3344 3345 3350 3354 3355 3360 3376 3381\n",
      " 3385 3390 3392 3393 3397 3400 3407 3412 3414 3423 3435 3437 3440 3443\n",
      " 3444 3447 3448 3452 3456 3457 3458 3459 3460 3462 3470 3474 3476 3482\n",
      " 3484 3490 3500 3504 3506 3512 3523 3534 3538 3554 3557 3570 3572 3580\n",
      " 3583 3586 3589 3592 3596 3598 3602 3604 3609 3619 3625 3626 3636 3637\n",
      " 3648 3649 3650 3663 3664 3665 3666 3668 3669 3673 3676 3683 3685 3692\n",
      " 3697 3700 3701 3705 3713 3717 3719 3721 3724 3736 3746 3748 3749 3755\n",
      " 3761 3768 3775 3776 3782 3788 3794 3801 3802 3804 3817 3818 3820 3821\n",
      " 3832 3837 3848 3849 3853 3861 3864 3874 3876 3878 3888 3890 3898 3907\n",
      " 3923 3931 3933 3937 3941 3950 3951 3953 3963 3969 3976 3982 3984 3986\n",
      " 3994 3995 3996 4005 4007 4015 4024 4028 4033 4034 4044 4047 4073 4077\n",
      " 4078 4079 4097 4098 4101 4103 4111 4112 4115 4121 4127 4132 4134 4138\n",
      " 4139 4145 4147 4151 4155 4166 4173 4174 4175]\n",
      "TRAIN: [   1    2    4 ... 4174 4175 4176] TEST: [   0    3    7   12   21   24   25   26   28   46   63   67   74   86\n",
      "   90   93   94   99  100  112  115  116  126  130  136  146  151  153\n",
      "  160  163  164  166  167  168  174  176  180  197  199  201  207  209\n",
      "  216  221  237  246  256  274  275  280  281  282  288  291  292  297\n",
      "  307  321  323  325  327  329  334  337  343  348  350  365  375  387\n",
      "  400  404  407  409  419  423  424  428  429  430  433  437  447  449\n",
      "  451  460  462  469  470  497  504  508  509  515  525  537  544  550\n",
      "  556  560  573  577  584  586  591  594  595  603  604  605  606  607\n",
      "  612  617  622  623  624  627  637  640  647  650  659  664  671  673\n",
      "  680  691  694  696  698  699  705  709  714  730  732  734  736  738\n",
      "  739  741  747  749  753  754  755  756  767  770  777  780  786  797\n",
      "  800  802  804  807  809  816  821  827  830  834  837  843  845  848\n",
      "  851  854  857  859  860  865  869  872  873  885  894  902  903  908\n",
      "  922  925  928  929  931  932  941  945  950  952  956  967  973  975\n",
      "  990 1004 1006 1007 1011 1020 1022 1028 1033 1040 1046 1048 1053 1066\n",
      " 1071 1072 1085 1090 1092 1104 1107 1111 1112 1113 1130 1131 1133 1134\n",
      " 1141 1144 1149 1152 1153 1159 1162 1163 1167 1172 1176 1177 1179 1181\n",
      " 1194 1198 1201 1202 1204 1206 1207 1208 1209 1215 1219 1221 1241 1243\n",
      " 1247 1249 1250 1251 1253 1272 1278 1289 1297 1298 1304 1305 1306 1308\n",
      " 1309 1314 1331 1333 1337 1346 1348 1350 1352 1353 1369 1381 1384 1389\n",
      " 1392 1395 1398 1400 1402 1404 1409 1413 1416 1425 1429 1434 1435 1438\n",
      " 1441 1443 1445 1447 1461 1468 1469 1470 1472 1479 1480 1483 1488 1497\n",
      " 1514 1517 1522 1531 1532 1541 1542 1546 1551 1552 1556 1558 1561 1562\n",
      " 1563 1565 1566 1574 1578 1579 1582 1584 1589 1596 1600 1605 1608 1617\n",
      " 1619 1623 1634 1638 1640 1641 1645 1653 1660 1667 1671 1672 1684 1690\n",
      " 1701 1705 1707 1718 1720 1722 1723 1731 1734 1740 1744 1747 1750 1769\n",
      " 1777 1792 1795 1799 1800 1805 1812 1822 1823 1834 1838 1844 1847 1849\n",
      " 1862 1863 1868 1871 1879 1883 1889 1896 1899 1904 1908 1910 1911 1913\n",
      " 1915 1924 1933 1938 1941 1954 1956 1963 1966 1967 1970 1971 1973 1975\n",
      " 1978 1986 1987 1993 2002 2003 2006 2008 2009 2011 2021 2022 2023 2040\n",
      " 2042 2046 2051 2059 2071 2080 2081 2084 2089 2091 2105 2107 2117 2120\n",
      " 2121 2135 2139 2141 2146 2150 2152 2154 2157 2159 2163 2169 2171 2173\n",
      " 2176 2177 2182 2185 2186 2187 2195 2197 2214 2217 2221 2222 2227 2237\n",
      " 2247 2251 2257 2260 2261 2269 2273 2274 2280 2282 2292 2296 2298 2304\n",
      " 2322 2334 2335 2338 2339 2341 2344 2352 2353 2354 2371 2375 2384 2387\n",
      " 2388 2389 2391 2392 2403 2405 2417 2418 2425 2431 2435 2440 2444 2446\n",
      " 2463 2467 2469 2471 2477 2492 2496 2498 2502 2503 2511 2516 2528 2536\n",
      " 2538 2546 2547 2550 2562 2582 2595 2599 2603 2607 2609 2610 2633 2642\n",
      " 2646 2659 2660 2665 2671 2676 2679 2681 2683 2684 2685 2687 2691 2693\n",
      " 2701 2711 2712 2721 2723 2732 2738 2742 2744 2745 2748 2749 2750 2753\n",
      " 2757 2758 2763 2766 2767 2775 2778 2782 2783 2786 2787 2798 2811 2813\n",
      " 2814 2818 2820 2825 2826 2827 2830 2834 2850 2851 2852 2854 2860 2863\n",
      " 2867 2880 2881 2882 2884 2893 2897 2899 2900 2903 2904 2908 2924 2930\n",
      " 2934 2937 2938 2956 2957 2965 2967 2974 2977 2987 2989 2995 2997 2999\n",
      " 3024 3026 3046 3052 3056 3057 3060 3064 3067 3083 3085 3089 3091 3107\n",
      " 3108 3113 3114 3115 3116 3123 3125 3128 3130 3143 3146 3148 3150 3152\n",
      " 3165 3166 3168 3186 3187 3191 3192 3200 3204 3205 3207 3208 3219 3220\n",
      " 3221 3224 3243 3246 3252 3264 3273 3277 3279 3280 3281 3282 3289 3290\n",
      " 3291 3292 3298 3299 3300 3310 3315 3317 3318 3330 3331 3332 3337 3341\n",
      " 3348 3356 3361 3362 3372 3386 3395 3396 3398 3413 3418 3419 3421 3425\n",
      " 3426 3432 3441 3445 3450 3451 3453 3455 3463 3465 3466 3468 3483 3486\n",
      " 3491 3498 3505 3510 3513 3516 3520 3531 3533 3547 3548 3550 3560 3561\n",
      " 3566 3579 3581 3587 3591 3608 3611 3612 3616 3622 3623 3624 3630 3635\n",
      " 3638 3642 3646 3647 3651 3661 3674 3678 3680 3695 3707 3709 3726 3729\n",
      " 3734 3740 3742 3744 3762 3763 3779 3781 3786 3796 3807 3816 3822 3834\n",
      " 3835 3840 3843 3846 3847 3854 3869 3879 3882 3884 3886 3891 3893 3894\n",
      " 3900 3901 3904 3906 3912 3918 3925 3926 3930 3936 3938 3942 3944 3947\n",
      " 3957 3959 3961 3964 4002 4003 4004 4009 4010 4023 4026 4038 4050 4056\n",
      " 4058 4060 4065 4067 4071 4081 4082 4099 4105 4106 4107 4108 4114 4123\n",
      " 4128 4136 4140 4143 4150 4152 4158 4159 4165]\n"
     ]
    }
   ],
   "source": [
    "for train_index , test_index in kfold.split(Y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    y_train ,y_test  = Y.iloc[train_index] ,Y.iloc[test_index]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_abalon = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_pred = svc_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2634730538922156"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_classifier_abalon = ExtraTreesRegressor(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=10,\n",
       "                    max_features='auto', max_leaf_nodes=None,\n",
       "                    min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                    min_samples_leaf=1, min_samples_split=2,\n",
       "                    min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "                    oob_score=False, random_state=None, verbose=0,\n",
       "                    warm_start=False)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_classifier_abalon.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_classifier_abalon_pred = extra_classifier_abalon.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5736681646968728"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_classifier_abalon.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_regressor_abalon = GradientBoostingRegressor(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=10,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_regressor_abalon.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_regressor_abalon_pred = gradient_regressor_abalon.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5406519765220024"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_regressor_abalon.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_regressor_abalon_Kfold = GradientBoostingRegressor(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=10,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_regressor_abalon_Kfold.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.93949572,  8.59121909, 11.41126302, 10.0385228 ,  8.55149984,\n",
       "       10.27081801, 10.68277561, 12.67742869,  9.10823721,  8.37360018,\n",
       "        7.51119854, 13.90321716, 12.73078333, 12.02049985, 10.27611574,\n",
       "       11.47599495, 15.14849021,  7.74319412,  7.3182539 ,  7.22618555,\n",
       "        9.08074283, 11.62346032,  7.73165259, 18.46872541,  7.21654625,\n",
       "        9.29405294, 10.87049466, 12.58041209, 12.21951569, 16.58171313,\n",
       "       18.14824965, 16.9188776 , 14.58605394, 23.06566745,  4.18591074,\n",
       "        6.54743413, 11.85254118, 13.31900164, 11.94245234, 14.29326192,\n",
       "        8.61116873,  8.0968223 ,  9.91156638, 11.39998805,  3.39063346,\n",
       "        6.7889003 , 14.75398708, 14.15103618, 17.25485177, 15.83936671,\n",
       "        8.58895103,  8.38576112, 13.67849004, 12.49428598, 11.19137669,\n",
       "        5.54610339, 20.62536699,  3.83283187,  6.38411561,  8.28415223,\n",
       "       12.02331196,  7.44899231, 12.86835635, 15.39810882,  8.37481676,\n",
       "       10.0325788 , 10.48357354, 10.96633036, 11.95720359,  8.10904678,\n",
       "        8.97652321,  5.92218095, 14.4928197 , 10.07605282, 12.81521581,\n",
       "        5.42446033,  6.35690177, 13.49902526, 16.46865516, 12.84981792,\n",
       "       11.05624528,  8.24601156, 14.16701413, 10.54512718, 11.19472109,\n",
       "        7.35898026,  5.41586901, 18.1927839 ,  9.54659405, 10.44212299,\n",
       "       21.88710721, 11.42662463, 11.97561735,  6.53462363,  4.39194777,\n",
       "        7.0686399 ,  8.336468  , 10.85096671,  9.81809063,  8.3265483 ,\n",
       "       10.75169098, 13.52477167,  7.14856814, 10.48787495,  8.33303478,\n",
       "       10.23912067, 14.42383938,  8.70863492, 12.42335762, 11.58994092,\n",
       "        6.10102567,  8.44791043,  7.79695662,  8.23843342, 12.6988905 ,\n",
       "        9.27708205,  8.98486377,  6.22757612,  6.38119043,  6.42871076,\n",
       "       11.83856913,  5.35556646, 11.86060859, 12.23821171, 16.51627099,\n",
       "        9.03916626,  8.38415484,  5.57924072,  3.02026857,  3.15689351,\n",
       "        8.9194161 , 11.95691318, 12.30733466,  5.5294321 ,  7.24279559,\n",
       "       14.37673199, 14.28877807, 13.81584029, 12.20662388, 16.97981881,\n",
       "        9.19709527,  6.65769082, 11.83686328, 10.70497608, 11.84582937,\n",
       "       16.87978039, 11.09984075, 13.63405136,  8.52596339, 13.08717281,\n",
       "       14.88018889, 16.35935067, 11.53218905,  7.58950857, 12.76980402,\n",
       "       11.74114642, 10.7844423 , 13.13884074, 12.3658613 ,  6.4588792 ,\n",
       "        6.5949256 ,  7.77408926,  6.86830773,  6.73286297,  9.56308097,\n",
       "       10.75427278,  8.29378934, 11.1502273 ,  9.48399847,  8.87811941,\n",
       "       11.75190301, 13.24271308, 10.2150563 ,  9.87447047, 11.41313586,\n",
       "       10.44123276, 19.75634115, 11.58799435,  4.72385751,  6.20122084,\n",
       "        7.06906307,  6.41726013,  7.06834667,  7.1791265 ,  8.21110045,\n",
       "       10.4592672 ,  7.91905046,  9.55655471,  7.06515249,  7.71985351,\n",
       "        8.326881  ,  7.35546705,  8.73628813,  8.01222216,  7.74715194,\n",
       "       13.05518487, 10.05629595, 11.73742345,  8.9931293 ,  9.89700881,\n",
       "        9.85991725, 10.99441085, 10.91673398, 10.95022758, 13.59263618,\n",
       "       11.50890265, 11.71816614, 11.31942104,  3.53827245,  6.19795133,\n",
       "        6.77813915,  7.27883752, 11.44052772,  8.30571435,  6.90578632,\n",
       "        7.93486693,  8.4303115 ,  8.30184003,  9.08102539,  8.19216076,\n",
       "        7.85184671,  8.25404155,  8.78257267,  8.54418311, 10.70250352,\n",
       "       10.09343704,  9.90067225,  9.21502712,  9.1793297 , 10.76412535,\n",
       "       10.19027962,  9.33031894,  8.71301778,  9.36987529, 11.05261975,\n",
       "       10.09388447,  9.7267391 , 10.7881662 , 10.57943922,  9.73539291,\n",
       "        9.16422987, 10.56523435, 13.0354699 , 11.16499331, 11.50685638,\n",
       "       12.57555569, 11.98797341,  5.76116852,  8.23075762,  6.72705587,\n",
       "        6.48312757,  5.53366277,  9.41689348,  7.72172773,  7.46093123,\n",
       "        7.89988911,  6.06714197,  7.39430916,  8.22343353,  7.94892974,\n",
       "        8.0645361 ,  8.70128859,  8.76523194,  9.27655831,  9.48987117,\n",
       "       10.39668864,  9.9805706 ,  9.10291772, 12.97187454, 12.27254875,\n",
       "       10.93943326, 12.30127486,  9.32942165,  9.43215276, 10.31738173,\n",
       "       12.01948607, 10.12160293, 10.26411205, 10.3767682 , 10.98445508,\n",
       "       10.64389316, 14.04919782, 14.58241339, 13.71388743, 10.72465814,\n",
       "       10.8730483 ,  9.97701128, 10.24043879,  9.82726579, 11.02036901,\n",
       "        3.80979779,  6.72931194,  7.36940475,  6.59315379,  7.76458744,\n",
       "        7.26191967,  6.88208706,  7.04987989,  8.23842781,  8.59761226,\n",
       "        7.97773959,  8.91846497,  8.21726016,  9.67063604,  9.95722522,\n",
       "       10.10940114, 13.73243836,  9.8125817 , 13.21988497, 11.65985992,\n",
       "       12.00590941,  3.4736811 ,  6.33654303,  6.2059691 ,  5.74497365,\n",
       "        7.01264494,  7.99282869,  7.52044631,  7.95071687,  6.73696661,\n",
       "        7.0640923 ,  8.04636785,  8.57611368,  9.96926023,  8.93146053,\n",
       "       12.47533158,  9.18210649,  8.83796222,  8.75648169,  7.63897368,\n",
       "        7.90907435,  9.15858446,  9.83546754,  9.52429324,  7.9893511 ,\n",
       "        8.5174159 , 10.01401803, 10.86937852, 11.10768188, 13.40863457,\n",
       "       11.60732132,  8.89363726,  9.16650464,  8.94927439,  9.25557131,\n",
       "       11.65768958, 10.46608551, 13.14001943, 11.75124915, 11.95053782,\n",
       "        9.45404923, 11.24669488, 10.04459142, 10.6522723 , 10.1634277 ,\n",
       "        9.16164741, 14.92845215,  9.36613501,  8.930837  , 10.44697107,\n",
       "        9.35133345, 13.27534952, 11.25370934,  7.72812092, 13.13042044,\n",
       "        8.96249409, 10.89263299,  9.04039879, 10.80254417, 11.0464114 ,\n",
       "       10.7213723 , 10.0556874 , 12.06380248,  7.75398338,  8.48999676,\n",
       "        9.93392015,  7.52481679, 10.52294799,  8.98573708,  8.39680621,\n",
       "       10.71497496, 10.58826928,  9.86787806,  9.74669171,  9.68110417,\n",
       "       12.58137454,  8.66705411, 13.16047172, 10.49584055, 11.7084457 ,\n",
       "        9.51134776,  9.72011672,  9.85133308,  9.28947312, 14.01235425,\n",
       "       10.72867739,  9.36796065,  9.60036203, 10.44636139, 10.7516642 ,\n",
       "       13.05878869, 14.04215359, 11.32154333, 10.45430389, 10.87373951,\n",
       "       13.59694645, 10.48438431,  4.05612472,  4.93350881,  5.68866583,\n",
       "        5.24605567,  6.87845241,  7.1992238 ,  7.78471831,  7.05769089,\n",
       "        8.10695401,  7.95983395,  9.25312145,  8.60396638,  6.5216731 ,\n",
       "        9.07955516,  7.01274535,  7.41374794,  7.50065108, 10.25094354,\n",
       "        9.64969274, 10.81456286, 10.8510606 , 14.8069985 ,  8.49059757,\n",
       "       11.01828142, 13.46772664,  6.78500187,  7.0669906 ,  8.79734395,\n",
       "       11.05221465, 17.6291219 ,  6.37857602,  9.68867524,  8.03444248,\n",
       "        8.17740166, 10.92134947, 23.18893286, 10.8388502 , 11.68984104,\n",
       "        2.85547354,  5.61475478, 13.63521557, 13.54530662, 15.84126449,\n",
       "       14.19183591,  9.26683896, 12.01546246, 14.07165593,  6.28734078,\n",
       "        9.71324835,  8.2607776 , 11.30335738, 17.8895361 , 13.12970307,\n",
       "        6.21745167, 15.62089093,  9.75819773, 11.8174597 , 13.57644214,\n",
       "       13.1807702 , 14.69584466,  9.58157902, 11.44900149, 24.17305656,\n",
       "        8.19795813,  8.22723852,  6.80794116,  9.77408739, 11.55157319,\n",
       "       11.83271529,  9.04772279, 12.43424018, 12.26027408, 11.17645445,\n",
       "       16.80926927,  5.16198505, 13.38385052, 12.75432666, 16.42273987,\n",
       "        9.7696938 ,  4.39037968,  8.18528868,  9.33143021, 11.21701827,\n",
       "       12.13977068,  9.97347473,  6.91254038,  7.34052369,  4.85490447,\n",
       "       10.55651027,  8.07348228, 10.65631694, 13.18819252, 15.64686081,\n",
       "       13.95231614, 11.97965935, 10.58002573, 13.98588502, 16.38361316,\n",
       "       11.44457825, 11.42776099, 17.43010053, 17.19794936, 10.73431956,\n",
       "       12.60947267, 14.29015475,  5.64239539,  6.03272984,  7.18751384,\n",
       "        8.68479765, 12.91403357, 13.01087905, 12.1887673 ,  5.28369105,\n",
       "        5.25009412,  5.17496149,  7.26906556,  9.27822987, 12.34284595,\n",
       "       10.02340365, 10.96278661, 10.52791856, 10.52259539,  9.41603445,\n",
       "        7.65164473,  8.47622972,  7.50710522,  8.20784531,  9.22718845,\n",
       "        9.22791039,  9.04583056, 10.84351558,  8.75163289, 10.32047873,\n",
       "       10.40779832,  9.75673166, 11.62308153, 10.77390959, 11.43014409,\n",
       "       10.40614648, 10.51857581,  4.02329909,  3.25835586,  9.32360356,\n",
       "        7.37217518,  7.42533839,  7.18432536,  7.09094963,  8.34114634,\n",
       "        8.49912432, 11.64151553,  8.6952681 ,  9.01274817,  8.31868592,\n",
       "        8.97131173, 10.77686835,  9.68987951, 10.30523833,  9.23641158,\n",
       "       11.41281443,  7.77593207, 10.62256147, 11.11860066,  9.29187279,\n",
       "       11.04971054, 10.04902735, 12.51416084,  5.98824633,  4.92988936,\n",
       "        6.48643522,  6.87615072,  7.64436091,  7.56066824,  8.10881689,\n",
       "        7.97014168,  8.9248221 ,  9.16928692, 15.9884079 ,  9.39374953,\n",
       "       10.26921556,  9.73773443, 12.35466585,  5.98240172, 10.09033262,\n",
       "        8.02972415,  8.99088059, 11.17488749, 10.03750697,  8.93857271,\n",
       "       10.00935188,  8.58498577,  8.77029082,  9.41844155,  9.84060725,\n",
       "       11.57185029, 10.9967604 , 10.16522576, 11.22219545, 11.32843955,\n",
       "       14.09655511, 11.35377343, 11.57482485,  9.92786723, 11.51669657,\n",
       "        6.9073159 ,  9.94215989,  8.21142273,  9.35346956, 10.49059819,\n",
       "       10.62174227,  9.41777727,  8.26870959, 10.46557324,  9.18441087,\n",
       "       13.45909156, 10.00473157, 10.77737591, 12.69481892, 11.90496982,\n",
       "        4.97115183,  5.02897112,  8.46448239,  9.53207919,  7.23723222,\n",
       "        8.78579292,  8.09056547,  7.27069815,  6.54051812,  8.00653577,\n",
       "       14.85716455, 11.3060678 , 10.04128413, 10.25985253,  3.95594887,\n",
       "       12.13319794, 17.20157699,  9.67515584,  8.07600985, 10.49087331,\n",
       "       13.30986939, 12.96432056,  7.32289709,  8.59171609, 10.34499998,\n",
       "        9.84402138, 13.69017057, 13.79227443,  7.58103675,  8.8011808 ,\n",
       "        7.29493437, 14.36771949, 12.95952485,  7.2990131 , 16.66359028,\n",
       "       14.37506717, 13.22027798,  8.09298575,  9.294043  , 10.38594799,\n",
       "       12.76299708, 14.18890038, 14.14767205, 13.2034498 , 11.69628207,\n",
       "       10.32788464,  8.84924508, 11.83661416,  9.86577744, 11.63789865,\n",
       "       11.51527145, 13.45373351, 11.05722713,  7.89417603,  6.50705234,\n",
       "        4.81251867, 10.24349813, 13.42700882, 10.68640689, 11.01090455,\n",
       "       12.58439679,  8.65536665,  7.74948432,  7.22273468,  7.99936262,\n",
       "       13.02669859, 17.22378195, 16.28761435, 15.19386431,  6.9286321 ,\n",
       "        8.71338051, 11.67770563, 10.9439583 , 10.08464165, 14.57422913,\n",
       "       10.18179447,  6.24962478, 10.11495423,  7.57402716,  8.41293243,\n",
       "       14.26902843, 10.01999272, 10.00435511, 13.97571496,  9.53411289,\n",
       "       11.05242846, 11.11626039,  8.38689384,  9.1263944 ,  9.71118801,\n",
       "       12.34415589, 10.17666955, 10.1613575 , 12.65375016, 10.43078772,\n",
       "       11.17427806,  6.39546642,  7.13043851,  8.47995062,  7.56117231,\n",
       "        8.42476487, 10.49813982,  9.40129313,  9.09642659, 10.24827035,\n",
       "        9.11836371, 10.08009351,  9.49524937,  8.91014231,  9.44743277,\n",
       "       11.88711584, 10.22574328,  9.84765292, 10.41602885, 10.46020778,\n",
       "        5.99367842,  7.93997472,  8.78846845,  7.29974141,  9.8704388 ,\n",
       "       10.13297496,  9.71170074, 10.37687418,  9.68538391, 10.928896  ,\n",
       "       10.35298612, 10.29930537,  9.60425014, 11.31431583, 10.52255513,\n",
       "        7.63839691, 14.08723706,  9.41244588, 11.04665015,  5.76161382,\n",
       "        7.27543977, 11.58202176, 11.1826615 ,  9.99553293, 10.33944967,\n",
       "       12.13465125,  7.14506375,  7.12992289, 10.89475985,  8.69075551,\n",
       "        8.50822655, 11.15927796, 11.64163551,  8.41981957,  8.77995082,\n",
       "       12.68239639, 13.16073349, 11.54328411, 12.25905699,  5.94365678,\n",
       "        8.71068293, 13.53308215,  9.60408907, 11.99654546,  9.2284318 ,\n",
       "        8.40184777, 13.44830246,  4.22291274, 10.57558011, 15.57630316,\n",
       "       10.42768223, 11.97393279, 12.96360529, 11.41967084,  7.48318467,\n",
       "        9.06162394, 17.13605133, 14.08523683, 10.74688114, 12.52806886,\n",
       "       14.9529386 ,  6.25153924,  9.01059585,  8.01181123,  8.1151478 ,\n",
       "       10.04343187,  9.48548984,  5.15738358,  6.17346504,  9.18587311,\n",
       "       10.18982969, 12.12317128, 10.26752939,  8.01364596,  7.87515087,\n",
       "        7.42752934,  8.14735408, 10.54580319, 10.48772269, 10.79087546,\n",
       "       11.78222729, 10.86656802,  6.84839838,  7.61540862,  7.8212443 ,\n",
       "        9.71364685,  9.70787282, 11.49498097, 15.64810484, 10.22899553,\n",
       "        6.22744106,  6.78497265,  8.08161103, 10.71048022,  7.40441597])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_regressor_abalon_Kfold.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48034408269901563"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_regressor_abalon_Kfold.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "radom_forest_abalon = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radom_forest_abalon.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "radom_forest_abalon_pred = radom_forest_abalon.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5385674861895942"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radom_forest_abalon.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "radom_forest_abalon_Kfold = RandomForestRegressor(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radom_forest_abalon_Kfold.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "radom_forest_abalon_Kfold_pred = radom_forest_abalon_Kfold.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5398347160845103"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radom_forest_abalon_Kfold.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glass Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Id','Ri','Na','Mg','Al','Si','K','Ca','Be','Fe','Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = pd.read_csv('glass.data',names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Ri</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Be</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>210</td>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211</td>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212</td>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213</td>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214</td>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id       Ri     Na   Mg    Al     Si     K    Ca    Be   Fe  Type\n",
       "209  210  1.51623  14.14  0.0  2.88  72.61  0.08  9.18  1.06  0.0     7\n",
       "210  211  1.51685  14.92  0.0  1.99  73.06  0.00  8.40  1.59  0.0     7\n",
       "211  212  1.52065  14.36  0.0  2.02  73.42  0.00  8.44  1.64  0.0     7\n",
       "212  213  1.51651  14.38  0.0  1.94  73.61  0.00  8.48  1.57  0.0     7\n",
       "213  214  1.51711  14.23  0.0  2.08  73.36  0.00  8.62  1.67  0.0     7"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = glass.iloc[:,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ri</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Be</th>\n",
       "      <th>Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Ri     Na   Mg    Al     Si     K    Ca    Be   Fe\n",
       "209  1.51623  14.14  0.0  2.88  72.61  0.08  9.18  1.06  0.0\n",
       "210  1.51685  14.92  0.0  1.99  73.06  0.00  8.40  1.59  0.0\n",
       "211  1.52065  14.36  0.0  2.02  73.42  0.00  8.44  1.64  0.0\n",
       "212  1.51651  14.38  0.0  1.94  73.61  0.00  8.48  1.57  0.0\n",
       "213  1.51711  14.23  0.0  2.08  73.36  0.00  8.62  1.67  0.0"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = glass.iloc[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "209    7\n",
       "210    7\n",
       "211    7\n",
       "212    7\n",
       "213    7\n",
       "Name: Type, Length: 214, dtype: int64"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_classifer_glass = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_classifer_glass.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_classifer_glass_pred = kn_classifer_glass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.7906976744186"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,kn_classifer_glass_pred) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_classifier_glass = DecisionTreeClassifier(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_classifier_glass.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_classifier_glass_pred = dec_tree_classifier_glass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.09302325581395"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,dec_tree_classifier_glass_pred) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_glass = SVC(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_glass.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_glass_pred = svc_glass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6976744186046512"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,svc_glass_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_glass_linear = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_glass_linear.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_glass_linear_pred=svc_glass_linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6046511627906976"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,svc_glass_linear_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree_class_glass = ExtraTreesClassifier(max_depth=10,criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "                     oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree_class_glass.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree_class_glass_pred = extra_tree_class_glass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6976744186046512"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,extra_tree_class_glass_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree_class_glass_entropy = ExtraTreesClassifier(max_depth=10,criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
       "                     max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "                     oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree_class_glass_entropy.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree_class_glass_entropy_pred =extra_tree_class_glass_entropy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7441860465116279"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,extra_tree_class_glass_entropy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradbost_classifer_glass = GradientBoostingClassifier(max_depth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=15,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradbost_classifer_glass.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradbost_classifer_glass_pred = gradbost_classifer_glass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7674418604651163"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,gradbost_classifer_glass_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_classifer_glass = RandomForestClassifier(max_depth=15,criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_classifer_glass.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_classifer_glass_pred = random_classifer_glass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7209302325581395"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,random_classifer_glass_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_classifer_glass_entropy = RandomForestClassifier(max_depth=15,criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_classifer_glass_entropy.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_classifer_glass_entropy_pred  =random_classifer_glass_entropy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7441860465116279"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,random_classifer_glass_entropy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "gausian_class_glass = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gausian_class_glass.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "gausian_class_glass_pred = gausian_class_glass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4883720930232558"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,gausian_class_glass_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
